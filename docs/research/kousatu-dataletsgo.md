# (理解用) Prism Lattice UI の統計結果をどう読むか / 何が言えるのか

対象読者: 実装には詳しいが, 統計検定や形式検査は学部レベルのエンジニア  
目的: "説明" ではなく, あなたがデータを見て自分で納得して判断できる状態になること

このメモは, `statistics-1703.md` の「修正後の正しいデータ」に基づきます. :contentReference[oaicite:0]{index=0}  
(注意: このファイルには E との比較も残っていますが, ここではあなたの方針どおり A-D を中心に理解します.)

---

## 0. まず結論を 1 行で言うと

今回の実験では, **形式健全性 (VR/TCR/RRR/CDR など) は A-D 全て 100% で天井に到達**している.  
したがって, **モデル構成の差は「正しく出せるか」ではなく, 「一発で出るか (RGR)」「待ち時間 (LAT)」「推定コスト (COST)」に現れる**. :contentReference[oaicite:1]{index=1} :contentReference[oaicite:2]{index=2}

---

## 1. 何を比較しているのか (最小の地図)

あなたのシステムは, ざっくりこう:

User text
  -> Stage1 (抽出/分解)
  -> Stage2 (詳細化/構造化)
  -> Stage3 (DSL を JSON で確定)
  -> Validator (schema/type/ref/cycle)
  -> React/Jotai への変換

ここで「モデル構成 A-D」は, Stage1-3 のどこに chat / mini を置くかの違い.

この実験が見たいのは大きく 2 系統:
- Layer1: 形式健全性 (形式的に壊れていないか)
- Layer4(実用性): 運用指標 (遅いか, 高いか, など)

---

## 2. 指標を "エンジニアの言葉" に翻訳する (チートシート)

### Layer1 系 (壊れないこと)
- VR (Validity Rate)
  - まず JSON として成立しているか, DSL として受理できるか.
- TCR (Type Consistency Rate)
  - 型検査に通るか (TS 型など, スキーマ由来の制約).
- RRR (Reference Resolution Rate)
  - 参照が解決できるか (存在しない ID を参照してないか).
- CDR (Cycle Dependency Rate)
  - 依存が循環していないか.

エンジニア的に言うと:
- VR は "パース / スキーマ入口で落ちるか"
- TCR/RRR/CDR は "中身の整合性 (静的検査で落ちるか)"

### Layer1 だけど "運用" に寄るやつ
- RGR (Regeneration-free Rate; 再生成なし率)
  - **1 回で通った割合**. つまり "リトライが必要だった割合" の裏返し.

重要: VR などが 100% でも, RGR が低いと **裏でリトライが走っていて遅く/高くなる**.

### Layer4 (実用性)
- LAT (Latency)
  - 体感待ち時間. ms の中央値が載っている.
- COST (Estimated API cost)
  - 推定コスト. 「単価」ではなく **実際の消費 (トークン等) を反映した結果**と考える.

---

## 3. 検定の読み方 (ここが分かると一気に楽になる)

### 3.1 「有意」って何
このファイルでは有意水準が:
- alpha = 0.05
- Bonferroni 補正後 alpha' = 0.005 (10 比較) :contentReference[oaicite:3]{index=3}

意味:
- 何度も比較すると "たまたま当たる" が増えるので, 閾値を厳しくしている.
- 表の `**` は「補正後も有意」. :contentReference[oaicite:4]{index=4}

### 3.2 「効果量」って何
p 値は "差があるっぽい" を言うだけ.
効果量は "どれくらいデカい差か" を言う.

このファイルでは:
- 比率系は Cohen's h (N/S/M/L のラベル付き)
- LAT/COST は r (N/S/M/L のラベル付き) :contentReference[oaicite:5]{index=5}

実務の感覚に落とすと:
- p が小さくて効果量が L なら, "誰が見ても違う" に近い.
- p が小さくても効果量が N/S なら, "統計的には違うが運用上は誤差扱いもあり得る".

---

## 4. 修正後データが言っていること (A-D 중심)

### 4.1 Layer1 は「壊れない」が天井 (A-D で差が消えた)
VR/TCR/RRR/CDR は A-D 全て 100% で, 比較の p 値も 1.000 になっている. :contentReference[oaicite:6]{index=6}

これが意味すること:
- 今の実験条件では, **DSL の制約設計 + バリデーション + 必要なら再生成**で,
  "形式的に壊れた UI" を最終成果物として出さない設計が成立している.
- モデルを変えても "最終的に通す" という意味では差が出ない.

ここで大事なのは:
- 「LLM が賢いから壊れない」ではなく,
- **壊れ方を形式化して, 壊れたら落とす (そしてやり直す) から壊れない**.

つまりこれは **形式検査の勝利**.

### 4.2 ただし RGR だけは差が残る = "裏でリトライしている"
RGR は:
- A: 100%
- B: 88%
- C: 100%
- D: 100%

で, B は A/C/D と比べて補正後も有意に低い (`**`) かつ効果量も M. :contentReference[oaicite:7]{index=7}

直感的な読み:
- B は "最終的には通る" が, **1 回で通りにくい**.
- 12% は「10 回に 1 回強」なので, サービスとしては無視しづらい.
  (ユーザーは 10 回中 1 回, 追加待ちを踏む.)

エンジニア的な含意:
- B を採用するなら, "リトライ前提の UX/非同期化/タイムアウト設計" が必要.
- 逆に A/C/D は "1 回で通る" ので, パイプラインの単純化余地がある.

### 4.3 LAT の差は極めて大きい (体感が変わる)
中央値は:
- A: 12603 ms
- B: 41366 ms
- C: 7638 ms
- D: 24764 ms

で, A-B, B-C, C-D など多くの比較が補正後有意で, 効果量も L が多い. :contentReference[oaicite:8]{index=8}

直感的な読み:
- C は 7.6 秒くらい, A は 12.6 秒くらい.
- D は 24.8 秒くらい.
- B は 41.4 秒くらい.

つまり:
- **C は現実的に「待てる」ゾーン**
- **B は「遅すぎて UX が崩れる」ゾーン**に入っている可能性が高い

ここで RGR と合わせて考えると:
- B は「遅い」上に「追加リトライも起きがち」なので,
  tail latency (遅いケースのさらに遅さ) が悪化しやすい.

### 4.4 COST も B が高い + 「中央値同じでも差が出る」ケースがある
中央値は:
- A: 3
- B: 4
- C: 3
- D: 3 :contentReference[oaicite:9]{index=9}

B は A/C/D に対して補正後有意に高い. :contentReference[oaicite:10]{index=10}

さらに面白いのは:
- A vs D: どちらも中央値 3 なのに, 補正後有意 (`**`) :contentReference[oaicite:11]{index=11}
- C vs D: どちらも中央値 3 なのに, 補正後有意 (`**`) :contentReference[oaicite:12]{index=12}

これが意味すること:
- **中央値だけ見ても分からない差が, 分布 (ばらつき / 裾の重さ) にある**
- 運用の観点では, 平均コストより「たまに爆発する」を警戒するべきことが多い

---

## 5. (理解の核) 今回の結果が "設計思想" として示していること

### 5.1 「LLM を賢くする」ではなく「壊れない枠を作る」
VR/TCR/RRR/CDR が天井に到達した, というのは
- 生成の自由度を DSL に閉じ込め
- 壊れたら機械的に落とす
- (必要なら) やり直す

という, 典型的な "hardened" アプローチが効いている, ということ. :contentReference[oaicite:13]{index=13}

これは, 研究のメッセージとして強い.
なぜなら, LLM の品質は変動するが, **検査器と DSL は自分で制御できる**から.

### 5.2 モデル選択問題が「成功率」から「運用最適化」に移る
A-D で成功率が揃った以上, モデル選択は:
- RGR (リトライ頻度)
- LAT (待ち時間)
- COST (推定コスト分布)

の最適化になる. :contentReference[oaicite:14]{index=14}

ここで初めて, システム工学っぽい意思決定になる:
- "どれが賢いか" ではなく,
- "SLO/予算/UX の制約下でどれが強いか".

---

## 6. 次にあなたが考えると理解が固まる問い (セルフチェック)

1

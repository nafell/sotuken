/**
 * Batch Experiment API Routes
 * /api/experiment/batch/* ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
 *
 * Layer1/Layer4è‡ªå‹•è©•ä¾¡å®Ÿé¨“ã®ãƒãƒƒãƒå®Ÿè¡ŒAPI
 * @see specs/system-design/experiment_spec_layer_1_layer_4.md
 */

import { Hono } from 'hono';
import { streamSSE } from 'hono/streaming';
import { db } from '../database/index';
import { batchExecutions, experimentTrialLogs } from '../database/schema';
import { eq, and, inArray } from 'drizzle-orm';
import {
  getBatchExecutionService,
  startBatch,
  stopBatch,
  getBatchProgress,
} from '../services/BatchExecutionService';
import {
  MODEL_CONFIGURATIONS,
  TOKEN_PRICES,
  USD_TO_JPY,
  type ModelConfigId,
  type Layer1Metrics,
  type Layer4Metrics,
  type ModelStatistics,
} from '../types/experiment-trial.types';

const batchExperimentRoutes = new Hono();

// ========================================
// ãƒãƒƒãƒå®Ÿè¡Œç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
// ========================================

/**
 * POST /api/experiment/batch/start
 * ãƒãƒƒãƒå®Ÿè¡Œã‚’é–‹å§‹
 */
batchExperimentRoutes.post('/start', async (c) => {
  try {
    const body = await c.req.json();
    const {
      experimentId,
      modelConfigs,
      inputCorpusId,
      parallelism = 1,
      headlessMode = true,
      maxTrials,
    } = body;

    // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if (!experimentId) {
      return c.json({
        success: false,
        error: 'experimentId is required'
      }, 400);
    }

    if (!Array.isArray(modelConfigs) || modelConfigs.length === 0) {
      return c.json({
        success: false,
        error: 'modelConfigs must be a non-empty array'
      }, 400);
    }

    // ãƒ¢ãƒ‡ãƒ«æ§‹æˆIDã®æ¤œè¨¼
    const validConfigIds = Object.keys(MODEL_CONFIGURATIONS);
    for (const configId of modelConfigs) {
      if (!validConfigIds.includes(configId)) {
        return c.json({
          success: false,
          error: `Invalid model config ID: ${configId}. Valid IDs: ${validConfigIds.join(', ')}`
        }, 400);
      }
    }

    if (!inputCorpusId) {
      return c.json({
        success: false,
        error: 'inputCorpusId is required'
      }, 400);
    }

    console.log(`ğŸš€ Starting batch experiment: ${experimentId}`);
    console.log(`  Model configs: ${modelConfigs.join(', ')}`);
    console.log(`  Input corpus: ${inputCorpusId}`);
    console.log(`  Parallelism: ${parallelism}`);
    console.log(`  Headless mode: ${headlessMode}`);
    console.log(`  Max trials: ${maxTrials ?? 'unlimited'}`);

    const result = await startBatch({
      experimentId,
      modelConfigs: modelConfigs as ModelConfigId[],
      inputCorpusId,
      parallelism,
      headlessMode,
      maxTrials,
    });

    return c.json({
      success: true,
      batchId: result.batchId,
      totalTrials: result.totalTrials,
      status: 'queued',
    });
  } catch (error) {
    console.error('Failed to start batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/status
 * ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/status', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // DBã‹ã‚‰ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    if (!batch) {
      return c.json({
        success: false,
        error: 'Batch not found'
      }, 404);
    }

    // ãƒ¡ãƒ¢ãƒªä¸Šã®é€²æ—æƒ…å ±ã‚’å–å¾—
    const progress = getBatchProgress(batchId);

    return c.json({
      success: true,
      batchId,
      experimentId: batch.experimentId,
      status: batch.status,
      progress: progress ?? {
        batchId,
        status: batch.status,
        totalTrials: batch.totalTrials,
        completedTrials: batch.completedTrials,
        failedTrials: batch.failedTrials,
      },
      startedAt: batch.startedAt,
      completedAt: batch.completedAt,
    });
  } catch (error) {
    console.error('Failed to get batch status:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * POST /api/experiment/batch/:batchId/stop
 * ãƒãƒƒãƒå®Ÿè¡Œã‚’åœæ­¢
 */
batchExperimentRoutes.post('/:batchId/stop', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    const stopped = await stopBatch(batchId);

    if (!stopped) {
      return c.json({
        success: false,
        error: 'Batch not found or not running'
      }, 404);
    }

    console.log(`ğŸ›‘ Batch ${batchId} stopped`);

    return c.json({
      success: true,
      message: 'Batch stopped'
    });
  } catch (error) {
    console.error('Failed to stop batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/progress
 * SSEã§é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡
 */
batchExperimentRoutes.get('/:batchId/progress', async (c) => {
  const batchId = c.req.param('batchId');

  return streamSSE(c, async (stream) => {
    let lastProgressJson = '';
    let iterations = 0;
    const maxIterations = 3600; // æœ€å¤§1æ™‚é–“ï¼ˆ1ç§’é–“éš”ï¼‰

    while (iterations < maxIterations) {
      const progress = getBatchProgress(batchId);

      if (!progress) {
        // DBã‹ã‚‰æœ€çµ‚çŠ¶æ…‹ã‚’å–å¾—
        const [batch] = await db
          .select()
          .from(batchExecutions)
          .where(eq(batchExecutions.id, batchId));

        if (batch) {
          await stream.writeSSE({
            event: 'complete',
            data: JSON.stringify({
              batchId,
              status: batch.status,
              totalTrials: batch.totalTrials,
              completedTrials: batch.completedTrials,
              failedTrials: batch.failedTrials,
            }),
          });
        }
        break;
      }

      // é€²æ—ãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã®ã¿é€ä¿¡ï¼ˆJSONå…¨ä½“ã‚’æ¯”è¼ƒï¼‰
      const progressJson = JSON.stringify(progress);
      if (progressJson !== lastProgressJson) {
        lastProgressJson = progressJson;

        await stream.writeSSE({
          event: 'progress',
          data: progressJson,
        });
      }

      // å®Œäº†ãƒã‚§ãƒƒã‚¯
      if (progress.status === 'completed' || progress.status === 'failed' || progress.status === 'stopped') {
        await stream.writeSSE({
          event: 'complete',
          data: progressJson,
        });
        break;
      }

      iterations++;
      await stream.sleep(1000); // 1ç§’é–“éš”
    }
  });
});

/**
 * Layer1/Layer4çµ±è¨ˆã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
function calculateStatistics(logs: typeof experimentTrialLogs.$inferSelect[]): {
  layer1: Layer1Metrics;
  layer4: Layer4Metrics;
} {
  if (logs.length === 0) {
    return {
      layer1: { VR: 0, TCR: 0, RRR: 0, CDR: 0, RGR: 0, W2WR_SR: 0, RC_SR: 0, JA_SR: 0 },
      layer4: { LAT: 0, COST: 0, FR: 0 },
    };
  }

  const total = logs.length;

  // Layer1è¨ˆç®—
  const validCount = logs.filter(
    log => (log.dslErrors === null || (Array.isArray(log.dslErrors) && log.dslErrors.length === 0)) &&
           (log.renderErrors === null || (Array.isArray(log.renderErrors) && log.renderErrors.length === 0))
  ).length;
  const typeOkCount = logs.filter(log => log.typeErrorCount === 0).length;
  const refOkCount = logs.filter(log => log.referenceErrorCount === 0).length;
  const cycleCount = logs.filter(log => log.cycleDetected).length;
  const regenCount = logs.filter(log => log.regenerated).length;

  // W2WR/RC/JA æˆåŠŸç‡è¨ˆç®—
  const w2wrSuccessCount = logs.filter(log => log.w2wrErrors === null).length;
  const rcSuccessCount = logs.filter(log => log.reactComponentErrors === null).length;
  const jaSuccessCount = logs.filter(log => log.jotaiAtomErrors === null).length;

  // Layer4è¨ˆç®—
  const totalLatency = logs.reduce((sum, log) => sum + log.latencyMs, 0);
  const runtimeErrorCount = logs.filter(log => log.runtimeError).length;

  // ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆæ¦‚ç®—ï¼‰
  let totalCostUsd = 0;
  for (const log of logs) {
    // ã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å®šï¼ˆmodelConfigã‹ã‚‰å–å¾—ã¯è¤‡é›‘ãªã®ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾¡æ ¼ã‚’ä½¿ç”¨ï¼‰
    const inputPricePerK = 0.010; // å¹³å‡çš„ãªä¾¡æ ¼
    const outputPricePerK = 0.030;
    const inputCost = (log.inputTokens / 1000) * inputPricePerK;
    const outputCost = (log.outputTokens / 1000) * outputPricePerK;
    totalCostUsd += inputCost + outputCost;
  }

  return {
    layer1: {
      VR: validCount / total,
      TCR: typeOkCount / total,
      RRR: refOkCount / total,
      CDR: cycleCount / total,
      RGR: regenCount / total,
      W2WR_SR: w2wrSuccessCount / total,
      RC_SR: rcSuccessCount / total,
      JA_SR: jaSuccessCount / total,
    },
    layer4: {
      LAT: totalLatency / total,
      COST: totalCostUsd * USD_TO_JPY,
      FR: runtimeErrorCount / total,
    },
  };
}

/**
 * GET /api/experiment/batch/:batchId/results
 * ãƒãƒƒãƒçµæœã‚µãƒãƒªãƒ¼ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/results', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    if (!batch) {
      return c.json({
        success: false,
        error: 'Batch not found'
      }, 404);
    }

    // è©¦è¡Œãƒ­ã‚°ã‚’å–å¾—
    const trialLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // ãƒ¢ãƒ‡ãƒ«æ§‹æˆåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    const logsByModel = new Map<string, typeof trialLogs>();
    for (const log of trialLogs) {
      const existing = logsByModel.get(log.modelConfig) ?? [];
      existing.push(log);
      logsByModel.set(log.modelConfig, existing);
    }

    // ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆã‚’è¨ˆç®—
    const byModel: ModelStatistics[] = [];
    for (const [modelConfig, logs] of logsByModel.entries()) {
      const stats = calculateStatistics(logs);
      byModel.push({
        modelConfig,
        trialCount: logs.length,
        layer1: stats.layer1,
        layer4: stats.layer4,
      });
    }

    // å…¨ä½“çµ±è¨ˆã‚’è¨ˆç®—
    const overallStats = calculateStatistics(trialLogs);

    // å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
    let totalDurationMs = 0;
    if (batch.startedAt && batch.completedAt) {
      totalDurationMs = new Date(batch.completedAt).getTime() - new Date(batch.startedAt).getTime();
    }

    // å®Œå…¨ãªã‚µãƒãƒªãƒ¼ã‚’æ§‹ç¯‰
    const summary = {
      batchId,
      experimentId: batch.experimentId,
      status: batch.status,
      totalTrials: batch.totalTrials,
      completedTrials: batch.completedTrials,
      failedTrials: batch.failedTrials,
      byModel,
      overall: overallStats,
      // è¨­å®šæƒ…å ±
      modelConfigs: batch.modelConfigs,
      inputCorpusId: batch.inputCorpusId,
      parallelism: batch.parallelism,
      maxTrials: batch.maxTrials,
      // ã‚¿ã‚¤ãƒŸãƒ³ã‚°
      startedAt: batch.startedAt,
      completedAt: batch.completedAt,
      totalDurationMs,
    };

    return c.json({
      success: true,
      summary,
      layer1Results: overallStats.layer1,
      layer4Results: overallStats.layer4,
    });
  } catch (error) {
    console.error('Failed to get batch results:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/trials
 * ãƒãƒƒãƒã®è©¦è¡Œãƒ­ã‚°ä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/trials', async (c) => {
  try {
    const batchId = c.req.param('batchId');
    const modelConfig = c.req.query('modelConfig');
    const stage = c.req.query('stage');

    let query = db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆåŸºæœ¬çš„ãªwhereå¥ã®ã¿ï¼‰
    const trialLogs = await query;

    // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    let filteredLogs = trialLogs;
    if (modelConfig) {
      filteredLogs = filteredLogs.filter(log => log.modelConfig === modelConfig);
    }
    if (stage) {
      filteredLogs = filteredLogs.filter(log => log.stage === parseInt(stage, 10));
    }

    return c.json({
      success: true,
      trials: filteredLogs,
      count: filteredLogs.length,
    });
  } catch (error) {
    console.error('Failed to get trial logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/export
 * ãƒãƒƒãƒçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
 */
batchExperimentRoutes.get('/:batchId/export', async (c) => {
  try {
    const batchId = c.req.param('batchId');
    const format = c.req.query('format') ?? 'json';

    // è©¦è¡Œãƒ­ã‚°ã‚’å–å¾—
    const trialLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    if (format === 'csv') {
      // CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
      const headers = [
        'experiment_id',
        'model_config',
        'stage',
        'input_tokens',
        'output_tokens',
        'latency_ms',
        'dsl_errors',
        'render_errors',
        'type_error_count',
        'reference_error_count',
        'cycle_detected',
        'regenerated',
        'runtime_error',
        'timestamp',
      ];

      const rows = trialLogs.map(log => [
        log.experimentId,
        log.modelConfig,
        log.stage,
        log.inputTokens,
        log.outputTokens,
        log.latencyMs,
        log.dslErrors ? JSON.stringify(log.dslErrors) : '',
        log.renderErrors ? JSON.stringify(log.renderErrors) : '',
        log.typeErrorCount,
        log.referenceErrorCount,
        log.cycleDetected,
        log.regenerated,
        log.runtimeError,
        log.timestamp,
      ]);

      const csvContent = [
        headers.join(','),
        ...rows.map(row => row.map(v => `"${v}"`).join(',')),
      ].join('\n');

      return new Response(csvContent, {
        headers: {
          'Content-Type': 'text/csv',
          'Content-Disposition': `attachment; filename="batch_${batchId}.csv"`,
        },
      });
    }

    // JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    return c.json({
      success: true,
      batchId,
      exportedAt: new Date().toISOString(),
      trialLogs,
    });
  } catch (error) {
    console.error('Failed to export batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch
 * ãƒãƒƒãƒä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/', async (c) => {
  try {
    const limit = parseInt(c.req.query('limit') ?? '20', 10);
    const offset = parseInt(c.req.query('offset') ?? '0', 10);

    const batches = await db
      .select()
      .from(batchExecutions)
      .orderBy(batchExecutions.createdAt)
      .limit(limit)
      .offset(offset);

    return c.json({
      success: true,
      batches,
      count: batches.length,
    });
  } catch (error) {
    console.error('Failed to get batches:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/configs
 * åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æ§‹æˆä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/configs', async (c) => {
  return c.json({
    success: true,
    configs: Object.entries(MODEL_CONFIGURATIONS).map(([id, config]) => ({
      id,
      name: config.name,
      stages: config.stages,
    })),
  });
});

/**
 * W2WRã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š
 * A: No W2WR, B: Passthrough, C: JSå˜ç´”, D: JSè¤‡åˆ, E: è¤‡æ•°Binding
 */
function classifyW2WRCategory(testCase: {
  hasReactivity?: boolean;
  expectedW2WR?: {
    bindings?: Array<{
      relationship?: { type?: string; javascript?: string };
    }>;
  };
}): 'A' | 'B' | 'C' | 'D' | 'E' {
  if (!testCase.hasReactivity) {
    return 'A'; // No W2WR
  }

  const bindings = testCase.expectedW2WR?.bindings ?? [];
  if (bindings.length === 0) {
    return 'A'; // No W2WR
  }

  if (bindings.length >= 2) {
    return 'E'; // è¤‡æ•°Binding
  }

  const binding = bindings[0];
  const relType = binding?.relationship?.type;

  if (relType === 'passthrough') {
    return 'B'; // Passthrough
  }

  if (relType === 'javascript') {
    const js = binding?.relationship?.javascript ?? '';
    // è¤‡åˆJSåˆ¤å®š: filter, Object.entries, flatMap ãªã©ãŒå«ã¾ã‚Œã‚‹ã‹
    const isComplex = /filter|Object\.entries|flatMap|reduce/.test(js);
    return isComplex ? 'D' : 'C';
  }

  return 'A'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
}

/**
 * GET /api/experiment/batch/corpuses
 * åˆ©ç”¨å¯èƒ½ãªå…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹ä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/corpuses', async (c) => {
  try {
    const fs = await import('fs/promises');
    const path = await import('path');

    interface CorpusInfo {
      corpusId: string;
      description: string;
      inputCount: number;
      metadata?: {
        w2wrDistribution: Record<string, number>;
        complexityDistribution: Record<string, number>;
        categoryDistribution: Record<string, number>;
      };
    }

    const corpuses: CorpusInfo[] = [];

    // 1. test_cases ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆconfig/test-cases/*.jsonï¼‰
    try {
      const testCasesDir = path.join(process.cwd(), '..', 'config', 'test-cases');
      const files = await fs.readdir(testCasesDir);
      const jsonFiles = files.filter(f => f.endsWith('.json')).sort();

      // ãƒ¡ã‚¿æƒ…å ±ã‚’é›†è¨ˆ
      const w2wrDistribution: Record<string, number> = { A: 0, B: 0, C: 0, D: 0, E: 0 };
      const complexityDistribution: Record<string, number> = {};
      const categoryDistribution: Record<string, number> = {};

      for (const file of jsonFiles) {
        const content = await fs.readFile(path.join(testCasesDir, file), 'utf-8');
        const testCase = JSON.parse(content);

        // W2WRåˆ†å¸ƒ
        const w2wrCategory = classifyW2WRCategory(testCase);
        w2wrDistribution[w2wrCategory] = (w2wrDistribution[w2wrCategory] ?? 0) + 1;

        // è¤‡é›‘åº¦åˆ†å¸ƒ
        const complexity = testCase.complexity ?? 'unknown';
        complexityDistribution[complexity] = (complexityDistribution[complexity] ?? 0) + 1;

        // ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        const category = testCase.contextFactors?.category ?? 'unknown';
        categoryDistribution[category] = (categoryDistribution[category] ?? 0) + 1;
      }

      corpuses.push({
        corpusId: 'test_cases',
        description: 'Expertè©•ä¾¡ç”¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹',
        inputCount: jsonFiles.length,
        metadata: {
          w2wrDistribution,
          complexityDistribution,
          categoryDistribution,
        },
      });
    } catch {
      // test-casesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }

    // 2. experiment-input-corpus.json ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    try {
      const corpusPath = path.join(process.cwd(), '..', 'config', 'experiment-input-corpus.json');
      const content = await fs.readFile(corpusPath, 'utf-8');
      const corpus = JSON.parse(content);
      corpuses.push({
        corpusId: corpus.corpusId || 'default',
        description: corpus.description || 'å…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹',
        inputCount: corpus.inputs?.length ?? 0,
      });
    } catch {
      // ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }

    return c.json({
      success: true,
      corpuses,
    });
  } catch (error) {
    console.error('Failed to list corpuses:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

export { batchExperimentRoutes };

/**
 * Batch Experiment API Routes
 * /api/experiment/batch/* ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
 *
 * Layer1/Layer4è‡ªå‹•è©•ä¾¡å®Ÿé¨“ã®ãƒãƒƒãƒå®Ÿè¡ŒAPI
 * @see specs/system-design/experiment_spec_layer_1_layer_4.md
 */

import { Hono } from 'hono';
import { streamSSE } from 'hono/streaming';
import { db } from '../database/index';
import { batchExecutions, experimentTrialLogs } from '../database/schema';
import { eq, and, inArray } from 'drizzle-orm';
import {
  getBatchExecutionService,
  startBatch,
  stopBatch,
  getBatchProgress,
} from '../services/BatchExecutionService';
import {
  MODEL_CONFIGURATIONS,
  TOKEN_PRICES_JPY_PER_MILLION,
  type ModelConfigId,
  type Layer1Metrics,
  type Layer4Metrics,
  type ModelStatistics,
  type ExperimentInput,
} from '../types/experiment-trial.types';
import { getStatisticalAnalysisService } from '../services/StatisticalAnalysisService';
import { exportToMarkdown, exportToCSV, exportSummaryTable } from '../services/StatisticalExportService';
import { createValidationService, validateUISpecForFrontend, getErrorSummary } from '../services/v4/ValidationService';
import { RevalidationLogger } from '../services/RevalidationLogger';
import { createExperimentOrchestrator } from '../services/ModelConfigurationService';
import { WidgetSelectionService } from '../services/v4/WidgetSelectionService';
import { ORSGeneratorService } from '../services/v4/ORSGeneratorService';
import { UISpecGeneratorV4 } from '../services/v4/UISpecGeneratorV4';
import { LLMOrchestrator } from '../services/v4/LLMOrchestrator';
import type { PlanUISpec } from '../types/v4/ui-spec.types';
import type { WidgetSelectionResult } from '../types/v4/widget-selection.types';
import type { PlanORS } from '../types/v4/ors.types';
import { LLM_ERROR_TYPES, type LLMCallMetrics } from '../types/v4/llm-task.types';

const batchExperimentRoutes = new Hono();

// UUIDå½¢å¼ã®æ¤œè¨¼ç”¨æ­£è¦è¡¨ç¾
const UUID_REGEX = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;

/**
 * batchIdãŒUUIDå½¢å¼ã‹ã©ã†ã‹ã‚’æ¤œè¨¼
 */
function isValidUUID(value: string): boolean {
  return UUID_REGEX.test(value);
}

// ========================================
// ãƒãƒƒãƒå®Ÿè¡Œç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
// ========================================

/**
 * POST /api/experiment/batch/start
 * ãƒãƒƒãƒå®Ÿè¡Œã‚’é–‹å§‹
 */
batchExperimentRoutes.post('/start', async (c) => {
  try {
    const body = await c.req.json();
    const {
      experimentId,
      modelConfigs,
      inputCorpusId,
      parallelism = 1,
      headlessMode = true,
      maxTrials,
    } = body;

    // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if (!experimentId) {
      return c.json({
        success: false,
        error: 'experimentId is required'
      }, 400);
    }

    if (!Array.isArray(modelConfigs) || modelConfigs.length === 0) {
      return c.json({
        success: false,
        error: 'modelConfigs must be a non-empty array'
      }, 400);
    }

    // ãƒ¢ãƒ‡ãƒ«æ§‹æˆIDã®æ¤œè¨¼
    const validConfigIds = Object.keys(MODEL_CONFIGURATIONS);
    for (const configId of modelConfigs) {
      if (!validConfigIds.includes(configId)) {
        return c.json({
          success: false,
          error: `Invalid model config ID: ${configId}. Valid IDs: ${validConfigIds.join(', ')}`
        }, 400);
      }
    }

    if (!inputCorpusId) {
      return c.json({
        success: false,
        error: 'inputCorpusId is required'
      }, 400);
    }

    console.log(`ğŸš€ Starting batch experiment: ${experimentId}`);
    console.log(`  Model configs: ${modelConfigs.join(', ')}`);
    console.log(`  Input corpus: ${inputCorpusId}`);
    console.log(`  Parallelism: ${parallelism}`);
    console.log(`  Headless mode: ${headlessMode}`);
    console.log(`  Max trials: ${maxTrials ?? 'unlimited'}`);

    const result = await startBatch({
      experimentId,
      modelConfigs: modelConfigs as ModelConfigId[],
      inputCorpusId,
      parallelism,
      headlessMode,
      maxTrials,
    });

    return c.json({
      success: true,
      batchId: result.batchId,
      totalTrials: result.totalTrials,
      status: 'queued',
    });
  } catch (error) {
    console.error('Failed to start batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/status
 * ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/status', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // DBã‹ã‚‰ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    if (!batch) {
      return c.json({
        success: false,
        error: 'Batch not found'
      }, 404);
    }

    // ãƒ¡ãƒ¢ãƒªä¸Šã®é€²æ—æƒ…å ±ã‚’å–å¾—
    const progress = getBatchProgress(batchId);

    return c.json({
      success: true,
      batchId,
      experimentId: batch.experimentId,
      status: batch.status,
      progress: progress ?? {
        batchId,
        status: batch.status,
        totalTrials: batch.totalTrials,
        completedTrials: batch.completedTrials,
        failedTrials: batch.failedTrials,
      },
      startedAt: batch.startedAt,
      completedAt: batch.completedAt,
    });
  } catch (error) {
    console.error('Failed to get batch status:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * POST /api/experiment/batch/:batchId/stop
 * ãƒãƒƒãƒå®Ÿè¡Œã‚’åœæ­¢
 */
batchExperimentRoutes.post('/:batchId/stop', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    const stopped = await stopBatch(batchId);

    if (!stopped) {
      return c.json({
        success: false,
        error: 'Batch not found or not running'
      }, 404);
    }

    console.log(`ğŸ›‘ Batch ${batchId} stopped`);

    return c.json({
      success: true,
      message: 'Batch stopped'
    });
  } catch (error) {
    console.error('Failed to stop batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/progress
 * SSEã§é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡
 */
batchExperimentRoutes.get('/:batchId/progress', async (c) => {
  const batchId = c.req.param('batchId');

  return streamSSE(c, async (stream) => {
    let lastProgressJson = '';
    let iterations = 0;
    const maxIterations = 3600; // æœ€å¤§1æ™‚é–“ï¼ˆ1ç§’é–“éš”ï¼‰

    while (iterations < maxIterations) {
      const progress = getBatchProgress(batchId);

      if (!progress) {
        // DBã‹ã‚‰æœ€çµ‚çŠ¶æ…‹ã‚’å–å¾—
        const [batch] = await db
          .select()
          .from(batchExecutions)
          .where(eq(batchExecutions.id, batchId));

        if (batch) {
          await stream.writeSSE({
            event: 'complete',
            data: JSON.stringify({
              batchId,
              status: batch.status,
              totalTrials: batch.totalTrials,
              completedTrials: batch.completedTrials,
              failedTrials: batch.failedTrials,
            }),
          });
        }
        break;
      }

      // é€²æ—ãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã®ã¿é€ä¿¡ï¼ˆJSONå…¨ä½“ã‚’æ¯”è¼ƒï¼‰
      const progressJson = JSON.stringify(progress);
      if (progressJson !== lastProgressJson) {
        lastProgressJson = progressJson;

        await stream.writeSSE({
          event: 'progress',
          data: progressJson,
        });
      }

      // å®Œäº†ãƒã‚§ãƒƒã‚¯
      if (progress.status === 'completed' || progress.status === 'failed' || progress.status === 'stopped') {
        await stream.writeSSE({
          event: 'complete',
          data: progressJson,
        });
        break;
      }

      iterations++;
      await stream.sleep(1000); // 1ç§’é–“éš”
    }
  });
});

/**
 * Layer1/Layer4çµ±è¨ˆã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
function calculateStatistics(logs: typeof experimentTrialLogs.$inferSelect[]): {
  layer1: Layer1Metrics;
  layer4: Layer4Metrics;
} {
  if (logs.length === 0) {
    return {
      layer1: { VR: 0, TCR: 0, RRR: 0, CDR: 0, RGR: 0, W2WR_SR: 0, RC_SR: 0, JA_SR: 0 },
      layer4: { LAT: 0, COST: 0, FR: 0 },
    };
  }

  const total = logs.length;

  // Layer1è¨ˆç®—
  const validCount = logs.filter(
    log => (log.dslErrors === null || (Array.isArray(log.dslErrors) && log.dslErrors.length === 0)) &&
           (log.renderErrors === null || (Array.isArray(log.renderErrors) && log.renderErrors.length === 0))
  ).length;
  const typeOkCount = logs.filter(log => log.typeErrorCount === 0).length;
  const refOkCount = logs.filter(log => log.referenceErrorCount === 0).length;
  const cycleCount = logs.filter(log => log.cycleDetected).length;
  const regenCount = logs.filter(log => log.regenerated).length;

  // W2WR/RC/JA æˆåŠŸç‡è¨ˆç®—
  const w2wrSuccessCount = logs.filter(log => log.w2wrErrors === null).length;
  const rcSuccessCount = logs.filter(log => log.reactComponentErrors === null).length;
  const jaSuccessCount = logs.filter(log => log.jotaiAtomErrors === null).length;

  // Layer4è¨ˆç®—
  const totalLatency = logs.reduce((sum, log) => sum + log.latencyMs, 0);
  const runtimeErrorCount = logs.filter(log => log.runtimeError).length;

  // ã‚³ã‚¹ãƒˆè¨ˆç®— (JPY) - Azure OpenAIæ–™é‡‘è¡¨ã‚ˆã‚Š
  let totalCostJPY = 0;
  for (const log of logs) {
    // GPT-4.1ç›¸å½“ã®ä¾¡æ ¼ã‚’ä½¿ç”¨ï¼ˆmodelConfigã”ã¨ã®è©³ç´°è¨ˆç®—ã¯ExperimentStatisticsServiceã§è¡Œã†ï¼‰
    const prices = TOKEN_PRICES_JPY_PER_MILLION['gpt-4.1'];
    const inputCost = (log.inputTokens / 1_000_000) * prices.input;
    const outputCost = (log.outputTokens / 1_000_000) * prices.output;
    totalCostJPY += inputCost + outputCost;
  }

  return {
    layer1: {
      VR: validCount / total,
      TCR: typeOkCount / total,
      RRR: refOkCount / total,
      CDR: cycleCount / total,
      RGR: regenCount / total,
      W2WR_SR: w2wrSuccessCount / total,
      RC_SR: rcSuccessCount / total,
      JA_SR: jaSuccessCount / total,
    },
    layer4: {
      LAT: totalLatency / total,
      COST: totalCostJPY,
      FR: runtimeErrorCount / total,
    },
  };
}

/**
 * GET /api/experiment/batch/:batchId/results
 * ãƒãƒƒãƒçµæœã‚µãƒãƒªãƒ¼ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/results', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    if (!batch) {
      return c.json({
        success: false,
        error: 'Batch not found'
      }, 404);
    }

    // è©¦è¡Œãƒ­ã‚°ã‚’å–å¾—
    const trialLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // ãƒ¢ãƒ‡ãƒ«æ§‹æˆåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    const logsByModel = new Map<string, typeof trialLogs>();
    for (const log of trialLogs) {
      const existing = logsByModel.get(log.modelConfig) ?? [];
      existing.push(log);
      logsByModel.set(log.modelConfig, existing);
    }

    // ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆã‚’è¨ˆç®—
    const byModel: ModelStatistics[] = [];
    for (const [modelConfig, logs] of logsByModel.entries()) {
      const stats = calculateStatistics(logs);
      byModel.push({
        modelConfig,
        trialCount: logs.length,
        layer1: stats.layer1,
        layer4: stats.layer4,
      });
    }

    // å…¨ä½“çµ±è¨ˆã‚’è¨ˆç®—
    const overallStats = calculateStatistics(trialLogs);

    // å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
    let totalDurationMs = 0;
    if (batch.startedAt && batch.completedAt) {
      totalDurationMs = new Date(batch.completedAt).getTime() - new Date(batch.startedAt).getTime();
    }

    // å®Œå…¨ãªã‚µãƒãƒªãƒ¼ã‚’æ§‹ç¯‰
    const summary = {
      batchId,
      experimentId: batch.experimentId,
      status: batch.status,
      totalTrials: batch.totalTrials,
      completedTrials: batch.completedTrials,
      failedTrials: batch.failedTrials,
      byModel,
      overall: overallStats,
      // è¨­å®šæƒ…å ±
      modelConfigs: batch.modelConfigs,
      inputCorpusId: batch.inputCorpusId,
      parallelism: batch.parallelism,
      maxTrials: batch.maxTrials,
      // ã‚¿ã‚¤ãƒŸãƒ³ã‚°
      startedAt: batch.startedAt,
      completedAt: batch.completedAt,
      totalDurationMs,
    };

    return c.json({
      success: true,
      summary,
      layer1Results: overallStats.layer1,
      layer4Results: overallStats.layer4,
    });
  } catch (error) {
    console.error('Failed to get batch results:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/trials
 * ãƒãƒƒãƒã®è©¦è¡Œãƒ­ã‚°ä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/trials', async (c) => {
  try {
    const batchId = c.req.param('batchId');
    const modelConfig = c.req.query('modelConfig');
    const stage = c.req.query('stage');

    let query = db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆåŸºæœ¬çš„ãªwhereå¥ã®ã¿ï¼‰
    const trialLogs = await query;

    // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    let filteredLogs = trialLogs;
    if (modelConfig) {
      filteredLogs = filteredLogs.filter(log => log.modelConfig === modelConfig);
    }
    if (stage) {
      filteredLogs = filteredLogs.filter(log => log.stage === parseInt(stage, 10));
    }

    return c.json({
      success: true,
      trials: filteredLogs,
      count: filteredLogs.length,
    });
  } catch (error) {
    console.error('Failed to get trial logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/export
 * ãƒãƒƒãƒçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
 */
batchExperimentRoutes.get('/:batchId/export', async (c) => {
  try {
    const batchId = c.req.param('batchId');
    const format = c.req.query('format') ?? 'json';

    // è©¦è¡Œãƒ­ã‚°ã‚’å–å¾—
    const trialLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    if (format === 'csv') {
      // CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
      const headers = [
        'experiment_id',
        'model_config',
        'stage',
        'input_tokens',
        'output_tokens',
        'latency_ms',
        'dsl_errors',
        'render_errors',
        'type_error_count',
        'reference_error_count',
        'cycle_detected',
        'regenerated',
        'runtime_error',
        'timestamp',
      ];

      const rows = trialLogs.map(log => [
        log.experimentId,
        log.modelConfig,
        log.stage,
        log.inputTokens,
        log.outputTokens,
        log.latencyMs,
        log.dslErrors ? JSON.stringify(log.dslErrors) : '',
        log.renderErrors ? JSON.stringify(log.renderErrors) : '',
        log.typeErrorCount,
        log.referenceErrorCount,
        log.cycleDetected,
        log.regenerated,
        log.runtimeError,
        log.timestamp,
      ]);

      const csvContent = [
        headers.join(','),
        ...rows.map(row => row.map(v => `"${v}"`).join(',')),
      ].join('\n');

      return new Response(csvContent, {
        headers: {
          'Content-Type': 'text/csv',
          'Content-Disposition': `attachment; filename="batch_${batchId}.csv"`,
        },
      });
    }

    // JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    return c.json({
      success: true,
      batchId,
      exportedAt: new Date().toISOString(),
      trialLogs,
    });
  } catch (error) {
    console.error('Failed to export batch:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch
 * ãƒãƒƒãƒä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/', async (c) => {
  try {
    const limit = parseInt(c.req.query('limit') ?? '20', 10);
    const offset = parseInt(c.req.query('offset') ?? '0', 10);

    const batches = await db
      .select()
      .from(batchExecutions)
      .orderBy(batchExecutions.createdAt)
      .limit(limit)
      .offset(offset);

    return c.json({
      success: true,
      batches,
      count: batches.length,
    });
  } catch (error) {
    console.error('Failed to get batches:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/configs
 * åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æ§‹æˆä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/configs', async (c) => {
  return c.json({
    success: true,
    configs: Object.entries(MODEL_CONFIGURATIONS).map(([id, config]) => ({
      id,
      name: config.name,
      stages: config.stages,
    })),
  });
});

/**
 * W2WRã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š
 * A: No W2WR, B: Passthrough, C: JSå˜ç´”, D: JSè¤‡åˆ, E: è¤‡æ•°Binding
 */
function classifyW2WRCategory(testCase: {
  hasReactivity?: boolean;
  expectedW2WR?: {
    bindings?: Array<{
      relationship?: { type?: string; javascript?: string };
    }>;
  };
}): 'A' | 'B' | 'C' | 'D' | 'E' {
  if (!testCase.hasReactivity) {
    return 'A'; // No W2WR
  }

  const bindings = testCase.expectedW2WR?.bindings ?? [];
  if (bindings.length === 0) {
    return 'A'; // No W2WR
  }

  if (bindings.length >= 2) {
    return 'E'; // è¤‡æ•°Binding
  }

  const binding = bindings[0];
  const relType = binding?.relationship?.type;

  if (relType === 'passthrough') {
    return 'B'; // Passthrough
  }

  if (relType === 'javascript') {
    const js = binding?.relationship?.javascript ?? '';
    // è¤‡åˆJSåˆ¤å®š: filter, Object.entries, flatMap ãªã©ãŒå«ã¾ã‚Œã‚‹ã‹
    const isComplex = /filter|Object\.entries|flatMap|reduce/.test(js);
    return isComplex ? 'D' : 'C';
  }

  return 'A'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
}

/**
 * GET /api/experiment/batch/corpuses
 * åˆ©ç”¨å¯èƒ½ãªå…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹ä¸€è¦§ã‚’å–å¾—
 */
batchExperimentRoutes.get('/corpuses', async (c) => {
  try {
    const fs = await import('fs/promises');
    const path = await import('path');

    interface CorpusInfo {
      corpusId: string;
      description: string;
      inputCount: number;
      metadata?: {
        w2wrDistribution: Record<string, number>;
        complexityDistribution: Record<string, number>;
        categoryDistribution: Record<string, number>;
      };
    }

    const corpuses: CorpusInfo[] = [];

    // 1. test_cases ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆconfig/test-cases/*.jsonï¼‰
    try {
      const testCasesDir = path.join(process.cwd(), '..', 'config', 'test-cases');
      const files = await fs.readdir(testCasesDir);
      const jsonFiles = files.filter(f => f.endsWith('.json')).sort();

      // ãƒ¡ã‚¿æƒ…å ±ã‚’é›†è¨ˆ
      const w2wrDistribution: Record<string, number> = { A: 0, B: 0, C: 0, D: 0, E: 0 };
      const complexityDistribution: Record<string, number> = {};
      const categoryDistribution: Record<string, number> = {};

      for (const file of jsonFiles) {
        const content = await fs.readFile(path.join(testCasesDir, file), 'utf-8');
        const testCase = JSON.parse(content);

        // W2WRåˆ†å¸ƒ
        const w2wrCategory = classifyW2WRCategory(testCase);
        w2wrDistribution[w2wrCategory] = (w2wrDistribution[w2wrCategory] ?? 0) + 1;

        // è¤‡é›‘åº¦åˆ†å¸ƒ
        const complexity = testCase.complexity ?? 'unknown';
        complexityDistribution[complexity] = (complexityDistribution[complexity] ?? 0) + 1;

        // ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        const category = testCase.contextFactors?.category ?? 'unknown';
        categoryDistribution[category] = (categoryDistribution[category] ?? 0) + 1;
      }

      corpuses.push({
        corpusId: 'test_cases',
        description: 'Expertè©•ä¾¡ç”¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹',
        inputCount: jsonFiles.length,
        metadata: {
          w2wrDistribution,
          complexityDistribution,
          categoryDistribution,
        },
      });
    } catch {
      // test-casesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }

    // 2. experiment-input-corpus.json ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    try {
      const corpusPath = path.join(process.cwd(), '..', 'config', 'experiment-input-corpus.json');
      const content = await fs.readFile(corpusPath, 'utf-8');
      const corpus = JSON.parse(content);
      corpuses.push({
        corpusId: corpus.corpusId || 'default',
        description: corpus.description || 'å…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹',
        inputCount: corpus.inputs?.length ?? 0,
      });
    } catch {
      // ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }

    return c.json({
      success: true,
      corpuses,
    });
  } catch (error) {
    console.error('Failed to list corpuses:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

// ========================================
// å†æ¤œè¨¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆLL-001/LL-002å¯¾å¿œï¼‰
// ========================================

/**
 * GET /api/experiment/batch/:batchId/unvalidated
 * æœªæ¤œè¨¼ã®ãƒ­ã‚°ä¸€è¦§ã‚’å–å¾—
 *
 * serverValidatedAt ãŒ null ã®Stage 3ãƒ­ã‚°ã‚’è¿”ã™
 */
batchExperimentRoutes.get('/:batchId/unvalidated', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // UUIDå½¢å¼ã®æ¤œè¨¼
    if (!isValidUUID(batchId)) {
      return c.json({
        success: false,
        error: `Invalid batch ID format: "${batchId}". Expected UUID format (e.g., "b845003f-a50f-4f51-a77c-c4256340a20e")`
      }, 400);
    }

    // Stage 3 ã‹ã¤ serverValidatedAt ãŒ null ã®ãƒ­ã‚°ã‚’å–å¾—
    const unvalidatedLogs = await db
      .select({
        id: experimentTrialLogs.id,
        trialNumber: experimentTrialLogs.trialNumber,
        inputId: experimentTrialLogs.inputId,
        modelConfig: experimentTrialLogs.modelConfig,
        stage: experimentTrialLogs.stage,
        generatedData: experimentTrialLogs.generatedData,
        timestamp: experimentTrialLogs.timestamp,
      })
      .from(experimentTrialLogs)
      .where(
        and(
          eq(experimentTrialLogs.batchId, batchId),
          eq(experimentTrialLogs.stage, 3)
        )
      );

    // serverValidatedAt ãŒ null ã®ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆDrizzle ã® isNull ãŒä½¿ãˆãªã„å ´åˆã®å›é¿ç­–ï¼‰
    const fullLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(
        and(
          eq(experimentTrialLogs.batchId, batchId),
          eq(experimentTrialLogs.stage, 3)
        )
      );

    const unvalidated = fullLogs.filter(log => log.serverValidatedAt === null);

    return c.json({
      success: true,
      unvalidatedCount: unvalidated.length,
      totalStage3Count: fullLogs.length,
      unvalidatedLogs: unvalidated.map(log => ({
        id: log.id,
        trialNumber: log.trialNumber,
        inputId: log.inputId,
        modelConfig: log.modelConfig,
        hasGeneratedData: log.generatedData !== null,
        timestamp: log.timestamp,
      })),
    });
  } catch (error) {
    console.error('Failed to get unvalidated logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/api-errors
 * API_ERRORä»˜ãã®è©¦è¡Œä¸€è¦§ã‚’å–å¾—
 *
 * dslErrorsã«API_ERRORãŒå«ã¾ã‚Œã‚‹è©¦è¡Œã‚’è¿”ã™
 */
batchExperimentRoutes.get('/:batchId/api-errors', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // UUIDå½¢å¼ã®æ¤œè¨¼
    if (!isValidUUID(batchId)) {
      return c.json({
        success: false,
        error: `Invalid batch ID format: "${batchId}". Expected UUID format (e.g., "b845003f-a50f-4f51-a77c-c4256340a20e")`
      }, 400);
    }

    // å…¨ãƒ­ã‚°ã‚’å–å¾—
    const allLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // API_ERRORã‚’å«ã‚€ãƒ­ã‚°ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    const apiErrorType = LLM_ERROR_TYPES.API_ERROR;
    const apiErrorLogs = allLogs.filter(log => {
      if (!log.dslErrors || !Array.isArray(log.dslErrors)) {
        return false;
      }
      // dslErrorsã«api_errorã‚’å«ã‚€ã‚‚ã®ã‚’æ¤œå‡º
      return (log.dslErrors as string[]).some(err =>
        err === apiErrorType || err.startsWith(apiErrorType)
      );
    });

    // Stageåˆ¥ã«é›†è¨ˆ
    const stageDistribution: Record<number, number> = {};
    const modelConfigDistribution: Record<string, number> = {};
    const inputIdSet = new Set<string>();

    for (const log of apiErrorLogs) {
      stageDistribution[log.stage] = (stageDistribution[log.stage] ?? 0) + 1;
      modelConfigDistribution[log.modelConfig] = (modelConfigDistribution[log.modelConfig] ?? 0) + 1;
      inputIdSet.add(log.inputId);
    }

    return c.json({
      success: true,
      apiErrorCount: apiErrorLogs.length,
      totalLogCount: allLogs.length,
      affectedInputCount: inputIdSet.size,
      stageDistribution,
      modelConfigDistribution,
      apiErrorLogs: apiErrorLogs.map(log => ({
        id: log.id,
        trialNumber: log.trialNumber,
        inputId: log.inputId,
        modelConfig: log.modelConfig,
        stage: log.stage,
        dslErrors: log.dslErrors,
        latencyMs: log.latencyMs,
        inputTokens: log.inputTokens,
        outputTokens: log.outputTokens,
        timestamp: log.timestamp,
      })),
    });
  } catch (error) {
    console.error('Failed to get API error logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * POST /api/experiment/batch/:batchId/revalidate
 * æœªæ¤œè¨¼ãƒ­ã‚°ã‚’å†æ¤œè¨¼
 *
 * æ©Ÿèƒ½ç¾ã‚’é‡è¦–ã—ãŸCLIå‡ºåŠ›ã§å®Ÿè¡Œéç¨‹ã¨å·®åˆ†ã‚’å¯è¦–åŒ–
 *
 * Body:
 * - logIds?: string[] - ç‰¹å®šã®ãƒ­ã‚°IDã®ã¿å†æ¤œè¨¼ï¼ˆçœç•¥æ™‚ã¯å…¨æœªæ¤œè¨¼ã‚’å¯¾è±¡ï¼‰
 * - rerunBackendValidation?: boolean - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¤œè¨¼ã‚‚å†å®Ÿè¡Œã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰
 * - writeLogFile?: boolean - ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰
 */
batchExperimentRoutes.post('/:batchId/revalidate', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // UUIDå½¢å¼ã®æ¤œè¨¼
    if (!isValidUUID(batchId)) {
      return c.json({
        success: false,
        error: `Invalid batch ID format: "${batchId}". Expected UUID format (e.g., "b845003f-a50f-4f51-a77c-c4256340a20e")`
      }, 400);
    }

    const body = await c.req.json().catch(() => ({}));
    const { logIds, rerunBackendValidation = false, writeLogFile = true } = body as {
      logIds?: string[];
      rerunBackendValidation?: boolean;
      writeLogFile?: boolean;
    };

    // ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    // å¯¾è±¡ãƒ­ã‚°ã‚’å–å¾—
    let targetLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(
        and(
          eq(experimentTrialLogs.batchId, batchId),
          eq(experimentTrialLogs.stage, 3)
        )
      );

    // logIdsãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿
    if (logIds && logIds.length > 0) {
      targetLogs = targetLogs.filter(log => logIds.includes(log.id));
    } else {
      // æœªæ¤œè¨¼ã®ã¿ã‚’å¯¾è±¡
      targetLogs = targetLogs.filter(log => log.serverValidatedAt === null);
    }

    if (targetLogs.length === 0) {
      console.log(`[revalidate] â”€ No logs to revalidate for batch ${batchId.slice(0, 8)}...`);
      return c.json({
        success: true,
        message: 'No logs to revalidate',
        revalidatedCount: 0,
      });
    }

    // ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
    const logger = new RevalidationLogger(batchId);
    logger.logHeader(targetLogs.length, {
      experimentId: batch?.experimentId,
      modelConfigs: batch?.modelConfigs as string[] | undefined,
      rerunBackendValidation,
    });

    const results: Array<{
      logId: string;
      success: boolean;
      error?: string;
    }> = [];

    for (const log of targetLogs) {
      const startTime = Date.now();

      try {
        if (!log.generatedData) {
          logger.logSkipped(log.id, 'No generated data available');
          results.push({
            logId: log.id,
            success: false,
            error: 'No generated data available',
          });
          continue;
        }

        // å†æ¤œè¨¼å‰ã®å€¤ã‚’ä¿å­˜
        const beforeState = {
          renderErrors: log.renderErrors,
          reactComponentErrors: log.reactComponentErrors,
          jotaiAtomErrors: log.jotaiAtomErrors,
          typeErrorCount: log.typeErrorCount,
          referenceErrorCount: log.referenceErrorCount,
          cycleDetected: log.cycleDetected,
          serverValidatedAt: log.serverValidatedAt,
        };

        // ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›æ¤œè¨¼ã‚’å®Ÿè¡Œ
        const frontendValidation = validateUISpecForFrontend(log.generatedData as PlanUISpec);

        // å†æ¤œè¨¼å¾Œã®å€¤
        const afterState = {
          renderErrors: frontendValidation.renderErrors,
          reactComponentErrors: frontendValidation.reactComponentErrors,
          jotaiAtomErrors: frontendValidation.jotaiAtomErrors,
          typeErrorCount: frontendValidation.typeErrorCount,
          referenceErrorCount: frontendValidation.referenceErrorCount,
          cycleDetected: frontendValidation.cycleDetected,
          serverValidatedAt: frontendValidation.serverValidatedAt,
        };

        // å·®åˆ†ã‚’è¨ˆç®—
        const diffs = [
          RevalidationLogger.createDiff('renderErrors', beforeState.renderErrors, afterState.renderErrors),
          RevalidationLogger.createDiff('reactComponentErrors', beforeState.reactComponentErrors, afterState.reactComponentErrors),
          RevalidationLogger.createDiff('jotaiAtomErrors', beforeState.jotaiAtomErrors, afterState.jotaiAtomErrors),
          RevalidationLogger.createDiff('typeErrorCount', beforeState.typeErrorCount, afterState.typeErrorCount),
          RevalidationLogger.createDiff('referenceErrorCount', beforeState.referenceErrorCount, afterState.referenceErrorCount),
          RevalidationLogger.createDiff('cycleDetected', beforeState.cycleDetected, afterState.cycleDetected),
        ];

        // DBæ›´æ–°
        await db
          .update(experimentTrialLogs)
          .set({
            renderErrors: frontendValidation.renderErrors,
            reactComponentErrors: frontendValidation.reactComponentErrors,
            jotaiAtomErrors: frontendValidation.jotaiAtomErrors,
            typeErrorCount: frontendValidation.typeErrorCount,
            referenceErrorCount: frontendValidation.referenceErrorCount,
            cycleDetected: frontendValidation.cycleDetected,
            serverValidatedAt: new Date(frontendValidation.serverValidatedAt),
          })
          .where(eq(experimentTrialLogs.id, log.id));

        const processingTimeMs = Date.now() - startTime;

        // é€²æ—ã‚’ãƒ­ã‚°
        logger.logProgress({
          logId: log.id,
          trialNumber: log.trialNumber,
          inputId: log.inputId,
          modelConfig: log.modelConfig,
          success: true,
          diffs,
          processingTimeMs,
        });

        results.push({
          logId: log.id,
          success: true,
        });
      } catch (err) {
        const processingTimeMs = Date.now() - startTime;
        const errorMessage = err instanceof Error ? err.message : 'Unknown error';

        logger.logProgress({
          logId: log.id,
          trialNumber: log.trialNumber,
          inputId: log.inputId,
          modelConfig: log.modelConfig,
          success: false,
          error: errorMessage,
          diffs: [],
          processingTimeMs,
        });

        results.push({
          logId: log.id,
          success: false,
          error: errorMessage,
        });
      }
    }

    // ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    const summary = logger.logSummary();

    // ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    let logFilePath: string | undefined;
    if (writeLogFile) {
      logFilePath = await logger.writeLogFile(summary);
    }

    const successCount = results.filter(r => r.success).length;
    const failCount = results.filter(r => !r.success).length;

    return c.json({
      success: true,
      revalidatedCount: successCount,
      failedCount: failCount,
      changedCount: summary.changedCount,
      unchangedCount: summary.unchangedCount,
      totalProcessingTimeMs: summary.totalProcessingTimeMs,
      logFilePath,
      diffSummary: summary.diffSummary.map(d => ({
        field: d.field,
        changedCount: d.changedCount,
      })),
      results,
    });
  } catch (error) {
    console.error('Failed to revalidate logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

// ========================================
// API_ERRORå†ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
// ========================================

/**
 * å…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã‚€ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
async function loadInputCorpus(corpusId: string): Promise<ExperimentInput[]> {
  const fs = await import('fs/promises');
  const path = await import('path');

  if (corpusId === 'test_cases') {
    const testCasesDir = path.join(process.cwd(), '..', 'config', 'test-cases');
    const files = await fs.readdir(testCasesDir);
    const jsonFiles = files.filter(f => f.endsWith('.json')).sort();

    const inputs: ExperimentInput[] = [];
    for (const file of jsonFiles) {
      const content = await fs.readFile(path.join(testCasesDir, file), 'utf-8');
      const testCase = JSON.parse(content);
      inputs.push({
        inputId: testCase.caseId,
        concernText: testCase.concernText,
        contextFactors: {
          category: testCase.contextFactors.category,
          urgency: testCase.contextFactors.urgency,
          emotionalState: testCase.contextFactors.emotionalState,
          timeAvailable: String(testCase.contextFactors.timeAvailable),
        },
      });
    }
    return inputs;
  }

  const corpusPath = path.join(process.cwd(), '..', 'config', 'experiment-input-corpus.json');
  const content = await fs.readFile(corpusPath, 'utf-8');
  const corpus = JSON.parse(content);
  return corpus.inputs ?? [];
}

/**
 * ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒ—æ¨å®š
 */
function inferBottleneckType(contextFactors: { emotionalState?: string }): string {
  const mapping: Record<string, string> = {
    'confused': 'information',
    'anxious': 'emotional',
    'overwhelmed': 'planning',
    'stuck': 'thought',
    'neutral': 'thought',
  };
  return mapping[contextFactors.emotionalState ?? 'neutral'] ?? 'thought';
}

/**
 * v4ã‚µãƒ¼ãƒ“ã‚¹ç¾¤ã‚’ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
 */
function createV4Services(orchestrator: LLMOrchestrator) {
  return {
    widgetSelectionService: new WidgetSelectionService({
      llmOrchestrator: orchestrator,
      debug: true,
    }),
    orsGeneratorService: new ORSGeneratorService({
      llmOrchestrator: orchestrator,
      debug: true,
      disableFallback: true,
    }),
    uiSpecGeneratorService: new UISpecGeneratorV4({
      llmOrchestrator: orchestrator,
      debug: true,
      disableFallback: true,
    }),
  };
}

/**
 * å˜ä¸€è©¦è¡Œã‚’å†ç”Ÿæˆã—ã¦æ—¢å­˜ãƒ­ã‚°ã‚’æ›´æ–°
 */
async function regenerateTrialAndUpdateLogs(
  batchId: string,
  experimentId: string,
  trialNumber: number,
  inputId: string,
  modelConfigId: ModelConfigId,
  input: ExperimentInput,
  existingLogIds: { stage1?: string; stage2?: string; stage3?: string }
): Promise<{
  success: boolean;
  stages: Array<{
    stage: number;
    success: boolean;
    logId?: string;
    error?: string;
  }>;
}> {
  const validationService = createValidationService();
  const orchestrator = createExperimentOrchestrator(modelConfigId);
  const services = createV4Services(orchestrator);
  const bottleneckType = inferBottleneckType(input.contextFactors);
  const sessionId = `regen-${batchId}-${trialNumber}-${Date.now()}`;

  const stageResults: Array<{
    stage: number;
    success: boolean;
    logId?: string;
    error?: string;
  }> = [];

  try {
    // ========================================
    // Stage 1: Widget Selection
    // ========================================
    const stage1Result = await services.widgetSelectionService.selectWidgets({
      concernText: input.concernText,
      bottleneckType,
      sessionId,
    });

    let stage1DslErrors: string[] | null = null;
    let stage1TypeErrorCount = 0;
    let stage1ReferenceErrorCount = 0;
    let stage1CycleDetected = false;

    if (stage1Result.success && stage1Result.data) {
      const validationResult = validationService.validateWidgetSelection(stage1Result.data);
      const summary = getErrorSummary(validationResult);
      stage1DslErrors = summary.dslErrors;
      stage1TypeErrorCount = summary.typeErrorCount;
      stage1ReferenceErrorCount = summary.referenceErrorCount;
      stage1CycleDetected = summary.cycleDetected;
    } else if (!stage1Result.success) {
      stage1DslErrors = [stage1Result.error?.type ?? 'WIDGET_SELECTION_FAILED'];
    }

    // Stage 1ãƒ­ã‚°ã‚’æ›´æ–°ã¾ãŸã¯æ–°è¦ä½œæˆ
    let stage1LogId = existingLogIds.stage1;
    if (stage1LogId) {
      await db.update(experimentTrialLogs)
        .set({
          inputTokens: stage1Result.metrics.inputTokens ?? 0,
          outputTokens: stage1Result.metrics.outputTokens ?? 0,
          latencyMs: stage1Result.metrics.latencyMs ?? 0,
          dslErrors: stage1DslErrors,
          typeErrorCount: stage1TypeErrorCount,
          referenceErrorCount: stage1ReferenceErrorCount,
          cycleDetected: stage1CycleDetected,
          regenerated: true,
          generatedData: stage1Result.data ?? null,
          promptData: stage1Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, bottleneckType },
          timestamp: new Date(),
        })
        .where(eq(experimentTrialLogs.id, stage1LogId));
    } else {
      const [inserted] = await db.insert(experimentTrialLogs)
        .values({
          experimentId,
          batchId,
          trialNumber,
          inputId,
          modelConfig: modelConfigId,
          modelRouterSelection: null,
          stage: 1,
          inputTokens: stage1Result.metrics.inputTokens ?? 0,
          outputTokens: stage1Result.metrics.outputTokens ?? 0,
          latencyMs: stage1Result.metrics.latencyMs ?? 0,
          dslErrors: stage1DslErrors,
          typeErrorCount: stage1TypeErrorCount,
          referenceErrorCount: stage1ReferenceErrorCount,
          cycleDetected: stage1CycleDetected,
          regenerated: true,
          runtimeError: false,
          generatedData: stage1Result.data ?? null,
          promptData: stage1Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, bottleneckType },
          serverValidatedAt: null,
          timestamp: new Date(),
        })
        .returning({ id: experimentTrialLogs.id });
      stage1LogId = inserted.id;
    }

    stageResults.push({
      stage: 1,
      success: stage1Result.success && stage1DslErrors === null,
      logId: stage1LogId,
    });

    if (!stage1Result.success || stage1DslErrors !== null) {
      return { success: false, stages: stageResults };
    }

    const widgetSelectionResult = stage1Result.data as WidgetSelectionResult;

    // ========================================
    // Stage 2: Plan ORS Generation
    // ========================================
    const stage2Result = await services.orsGeneratorService.generatePlanORS({
      concernText: input.concernText,
      bottleneckType,
      widgetSelectionResult,
      sessionId,
    });

    let stage2DslErrors: string[] | null = null;
    let stage2TypeErrorCount = 0;
    let stage2ReferenceErrorCount = 0;
    let stage2CycleDetected = false;

    if (stage2Result.success && stage2Result.data) {
      const validationResult = validationService.validatePlanORS(stage2Result.data);
      const summary = getErrorSummary(validationResult);
      stage2DslErrors = summary.dslErrors;
      stage2TypeErrorCount = summary.typeErrorCount;
      stage2ReferenceErrorCount = summary.referenceErrorCount;
      stage2CycleDetected = summary.cycleDetected;
    } else if (!stage2Result.success) {
      stage2DslErrors = [stage2Result.error?.type ?? 'ORS_GENERATION_FAILED'];
    }

    // Stage 2ãƒ­ã‚°ã‚’æ›´æ–°ã¾ãŸã¯æ–°è¦ä½œæˆ
    let stage2LogId = existingLogIds.stage2;
    if (stage2LogId) {
      await db.update(experimentTrialLogs)
        .set({
          inputTokens: stage2Result.metrics.inputTokens ?? 0,
          outputTokens: stage2Result.metrics.outputTokens ?? 0,
          latencyMs: stage2Result.metrics.latencyMs ?? 0,
          dslErrors: stage2DslErrors,
          typeErrorCount: stage2TypeErrorCount,
          referenceErrorCount: stage2ReferenceErrorCount,
          cycleDetected: stage2CycleDetected,
          regenerated: true,
          generatedData: stage2Result.data ?? null,
          promptData: stage2Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, bottleneckType },
          timestamp: new Date(),
        })
        .where(eq(experimentTrialLogs.id, stage2LogId));
    } else {
      const [inserted] = await db.insert(experimentTrialLogs)
        .values({
          experimentId,
          batchId,
          trialNumber,
          inputId,
          modelConfig: modelConfigId,
          modelRouterSelection: null,
          stage: 2,
          inputTokens: stage2Result.metrics.inputTokens ?? 0,
          outputTokens: stage2Result.metrics.outputTokens ?? 0,
          latencyMs: stage2Result.metrics.latencyMs ?? 0,
          dslErrors: stage2DslErrors,
          typeErrorCount: stage2TypeErrorCount,
          referenceErrorCount: stage2ReferenceErrorCount,
          cycleDetected: stage2CycleDetected,
          regenerated: true,
          runtimeError: false,
          generatedData: stage2Result.data ?? null,
          promptData: stage2Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, bottleneckType },
          serverValidatedAt: null,
          timestamp: new Date(),
        })
        .returning({ id: experimentTrialLogs.id });
      stage2LogId = inserted.id;
    }

    stageResults.push({
      stage: 2,
      success: stage2Result.success && stage2DslErrors === null,
      logId: stage2LogId,
    });

    if (!stage2Result.success || stage2DslErrors !== null) {
      return { success: false, stages: stageResults };
    }

    const planORS = stage2Result.data as PlanORS;

    // ========================================
    // Stage 3: Plan UISpec Generation
    // ========================================
    const stage3Result = await services.uiSpecGeneratorService.generatePlanUISpec({
      planORS,
      concernText: input.concernText,
      widgetSelectionResult,
      sessionId,
      enableReactivity: true,
    });

    let stage3DslErrors: string[] | null = null;
    let stage3W2wrErrors: string[] | null = null;
    let stage3TypeErrorCount = 0;
    let stage3ReferenceErrorCount = 0;
    let stage3CycleDetected = false;

    if (stage3Result.success && stage3Result.data) {
      const validationResult = validationService.validateUISpec(stage3Result.data, widgetSelectionResult);
      const summary = getErrorSummary(validationResult);
      stage3TypeErrorCount = summary.typeErrorCount;
      stage3ReferenceErrorCount = summary.referenceErrorCount;
      stage3CycleDetected = summary.cycleDetected;

      if (!validationResult.valid) {
        const allErrors = validationResult.errors.map(e => e.type);
        const w2wrTypes = ['CIRCULAR_DEPENDENCY', 'SELF_REFERENCE', 'INVALID_BINDING',
                         'UNKNOWN_SOURCE_WIDGET', 'UNKNOWN_TARGET_WIDGET'];
        const w2wrFound = allErrors.filter(e => w2wrTypes.includes(e));
        const dslFound = allErrors.filter(e => !w2wrTypes.includes(e));
        stage3W2wrErrors = w2wrFound.length > 0 ? w2wrFound : null;
        stage3DslErrors = dslFound.length > 0 ? dslFound : null;
      }
    } else if (!stage3Result.success) {
      stage3DslErrors = [stage3Result.error?.type ?? 'UISPEC_GENERATION_FAILED'];
    }

    // ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›æ¤œè¨¼
    const frontendValidation = stage3Result.success && stage3Result.data
      ? validateUISpecForFrontend(stage3Result.data as PlanUISpec)
      : undefined;

    // Stage 3ãƒ­ã‚°ã‚’æ›´æ–°ã¾ãŸã¯æ–°è¦ä½œæˆ
    let stage3LogId = existingLogIds.stage3;
    if (stage3LogId) {
      await db.update(experimentTrialLogs)
        .set({
          inputTokens: stage3Result.metrics.inputTokens ?? 0,
          outputTokens: stage3Result.metrics.outputTokens ?? 0,
          latencyMs: stage3Result.metrics.latencyMs ?? 0,
          dslErrors: stage3DslErrors,
          w2wrErrors: stage3W2wrErrors,
          renderErrors: frontendValidation?.renderErrors ?? null,
          reactComponentErrors: frontendValidation?.reactComponentErrors ?? null,
          jotaiAtomErrors: frontendValidation?.jotaiAtomErrors ?? null,
          typeErrorCount: frontendValidation?.typeErrorCount ?? stage3TypeErrorCount,
          referenceErrorCount: frontendValidation?.referenceErrorCount ?? stage3ReferenceErrorCount,
          cycleDetected: frontendValidation?.cycleDetected ?? stage3CycleDetected,
          regenerated: true,
          generatedData: stage3Result.data ?? null,
          promptData: stage3Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, enableReactivity: true },
          serverValidatedAt: frontendValidation ? new Date(frontendValidation.serverValidatedAt) : null,
          timestamp: new Date(),
        })
        .where(eq(experimentTrialLogs.id, stage3LogId));
    } else {
      const [inserted] = await db.insert(experimentTrialLogs)
        .values({
          experimentId,
          batchId,
          trialNumber,
          inputId,
          modelConfig: modelConfigId,
          modelRouterSelection: null,
          stage: 3,
          inputTokens: stage3Result.metrics.inputTokens ?? 0,
          outputTokens: stage3Result.metrics.outputTokens ?? 0,
          latencyMs: stage3Result.metrics.latencyMs ?? 0,
          dslErrors: stage3DslErrors,
          w2wrErrors: stage3W2wrErrors,
          renderErrors: frontendValidation?.renderErrors ?? null,
          reactComponentErrors: frontendValidation?.reactComponentErrors ?? null,
          jotaiAtomErrors: frontendValidation?.jotaiAtomErrors ?? null,
          typeErrorCount: frontendValidation?.typeErrorCount ?? stage3TypeErrorCount,
          referenceErrorCount: frontendValidation?.referenceErrorCount ?? stage3ReferenceErrorCount,
          cycleDetected: frontendValidation?.cycleDetected ?? stage3CycleDetected,
          regenerated: true,
          runtimeError: false,
          generatedData: stage3Result.data ?? null,
          promptData: stage3Result.prompt ?? null,
          inputVariables: { concernText: input.concernText, enableReactivity: true },
          serverValidatedAt: frontendValidation ? new Date(frontendValidation.serverValidatedAt) : null,
          timestamp: new Date(),
        })
        .returning({ id: experimentTrialLogs.id });
      stage3LogId = inserted.id;
    }

    stageResults.push({
      stage: 3,
      success: stage3Result.success && stage3DslErrors === null,
      logId: stage3LogId,
    });

    const overallSuccess = stageResults.every(s => s.success);
    return { success: overallSuccess, stages: stageResults };

  } catch (error) {
    console.error(`Regeneration failed for trial ${trialNumber}:`, error);
    return {
      success: false,
      stages: stageResults.concat([{
        stage: stageResults.length + 1,
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      }]),
    };
  }
}

/**
 * POST /api/experiment/batch/:batchId/regenerate
 * API_ERRORä»˜ãã®è©¦è¡Œã‚’å†ç”Ÿæˆ
 *
 * Body:
 * - logIds?: string[] - ç‰¹å®šã®ãƒ­ã‚°IDã®ã¿å†ç”Ÿæˆï¼ˆçœç•¥æ™‚ã¯å…¨API_ERRORã‚’å¯¾è±¡ï¼‰
 * - dryRun?: boolean - trueã®å ´åˆã€å®Ÿéš›ã®å†ç”Ÿæˆã¯è¡Œã‚ãšå½±éŸ¿ç¯„å›²ã®ã¿è¿”ã™
 */
batchExperimentRoutes.post('/:batchId/regenerate', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    // UUIDå½¢å¼ã®æ¤œè¨¼
    if (!isValidUUID(batchId)) {
      return c.json({
        success: false,
        error: `Invalid batch ID format: "${batchId}". Expected UUID format`
      }, 400);
    }

    const body = await c.req.json().catch(() => ({}));
    const { logIds, dryRun = false } = body as {
      logIds?: string[];
      dryRun?: boolean;
    };

    // ãƒãƒƒãƒæƒ…å ±ã‚’å–å¾—
    const [batch] = await db
      .select()
      .from(batchExecutions)
      .where(eq(batchExecutions.id, batchId));

    if (!batch) {
      return c.json({
        success: false,
        error: 'Batch not found'
      }, 404);
    }

    // å…¨ãƒ­ã‚°ã‚’å–å¾—
    const allLogs = await db
      .select()
      .from(experimentTrialLogs)
      .where(eq(experimentTrialLogs.batchId, batchId));

    // API_ERRORã‚’å«ã‚€ãƒ­ã‚°ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    const apiErrorType = LLM_ERROR_TYPES.API_ERROR;
    let targetLogs = allLogs.filter(log => {
      if (!log.dslErrors || !Array.isArray(log.dslErrors)) {
        return false;
      }
      return (log.dslErrors as string[]).some(err =>
        err === apiErrorType || err.startsWith(apiErrorType)
      );
    });

    // logIdsãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿
    if (logIds && logIds.length > 0) {
      targetLogs = targetLogs.filter(log => logIds.includes(log.id));
    }

    if (targetLogs.length === 0) {
      return c.json({
        success: true,
        message: 'No API_ERROR logs to regenerate',
        regeneratedCount: 0,
      });
    }

    // è©¦è¡Œç•ªå·+ãƒ¢ãƒ‡ãƒ«æ§‹æˆã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆåŒã˜è©¦è¡Œã®å…¨Stageã‚’å†ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
    const trialGroups = new Map<string, typeof targetLogs>();
    for (const log of targetLogs) {
      const key = `${log.trialNumber}-${log.modelConfig}`;
      if (!trialGroups.has(key)) {
        trialGroups.set(key, []);
      }
      trialGroups.get(key)!.push(log);
    }

    // å½±éŸ¿ã‚’å—ã‘ã‚‹è©¦è¡Œã®å…¨Stageã‚’å–å¾—
    const affectedTrials: Array<{
      trialNumber: number;
      modelConfig: string;
      inputId: string;
      existingLogIds: { stage1?: string; stage2?: string; stage3?: string };
      apiErrorStages: number[];
    }> = [];

    for (const [key, logs] of trialGroups) {
      const firstLog = logs[0];
      const trialNumber = firstLog.trialNumber;
      const modelConfig = firstLog.modelConfig;
      const inputId = firstLog.inputId;

      // ã“ã®è©¦è¡Œã®å…¨Stageãƒ­ã‚°ã‚’å–å¾—
      const trialLogs = allLogs.filter(
        log => log.trialNumber === trialNumber && log.modelConfig === modelConfig
      );

      const existingLogIds: { stage1?: string; stage2?: string; stage3?: string } = {};
      for (const log of trialLogs) {
        if (log.stage === 1) existingLogIds.stage1 = log.id;
        if (log.stage === 2) existingLogIds.stage2 = log.id;
        if (log.stage === 3) existingLogIds.stage3 = log.id;
      }

      affectedTrials.push({
        trialNumber,
        modelConfig,
        inputId,
        existingLogIds,
        apiErrorStages: logs.map(l => l.stage),
      });
    }

    // dryRunã®å ´åˆã¯å½±éŸ¿ç¯„å›²ã®ã¿è¿”ã™
    if (dryRun) {
      return c.json({
        success: true,
        dryRun: true,
        affectedTrialCount: affectedTrials.length,
        affectedTrials: affectedTrials.map(t => ({
          trialNumber: t.trialNumber,
          modelConfig: t.modelConfig,
          inputId: t.inputId,
          apiErrorStages: t.apiErrorStages,
        })),
      });
    }

    // å…¥åŠ›ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã¿
    const inputCorpus = await loadInputCorpus(batch.inputCorpusId);
    const inputMap = new Map(inputCorpus.map(i => [i.inputId, i]));

    console.log(`ğŸ”„ Regenerating ${affectedTrials.length} trials for batch ${batchId}`);

    const results: Array<{
      trialNumber: number;
      modelConfig: string;
      success: boolean;
      stages: Array<{ stage: number; success: boolean; error?: string }>;
    }> = [];

    for (const trial of affectedTrials) {
      const input = inputMap.get(trial.inputId);
      if (!input) {
        results.push({
          trialNumber: trial.trialNumber,
          modelConfig: trial.modelConfig,
          success: false,
          stages: [{ stage: 0, success: false, error: `Input not found: ${trial.inputId}` }],
        });
        continue;
      }

      console.log(`  Regenerating trial ${trial.trialNumber} (${trial.modelConfig})...`);

      const result = await regenerateTrialAndUpdateLogs(
        batchId,
        batch.experimentId,
        trial.trialNumber,
        trial.inputId,
        trial.modelConfig as ModelConfigId,
        input,
        trial.existingLogIds
      );

      results.push({
        trialNumber: trial.trialNumber,
        modelConfig: trial.modelConfig,
        success: result.success,
        stages: result.stages,
      });
    }

    const successCount = results.filter(r => r.success).length;
    const failCount = results.filter(r => !r.success).length;

    console.log(`âœ… Regeneration complete: ${successCount} success, ${failCount} failed`);

    return c.json({
      success: true,
      regeneratedCount: successCount,
      failedCount: failCount,
      results,
    });
  } catch (error) {
    console.error('Failed to regenerate logs:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

// ========================================
// çµ±è¨ˆåˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
// ========================================

/**
 * GET /api/experiment/batch/:batchId/statistics
 * ãƒãƒƒãƒã®çµ±è¨ˆæ¤œå®šçµæœã‚’å–å¾—
 */
batchExperimentRoutes.get('/:batchId/statistics', async (c) => {
  try {
    const batchId = c.req.param('batchId');

    const statisticsService = getStatisticalAnalysisService();
    const result = await statisticsService.runAllPairwiseComparisons(batchId);

    if (!result) {
      return c.json({
        success: false,
        error: 'Batch not found or no trial data available'
      }, 404);
    }

    return c.json({
      success: true,
      data: result,
    });
  } catch (error) {
    console.error('Failed to get statistics:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/experiment/batch/:batchId/statistics/export
 * çµ±è¨ˆæ¤œå®šçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
 */
batchExperimentRoutes.get('/:batchId/statistics/export', async (c) => {
  try {
    const batchId = c.req.param('batchId');
    const format = c.req.query('format') ?? 'markdown';

    const statisticsService = getStatisticalAnalysisService();
    const result = await statisticsService.runAllPairwiseComparisons(batchId);

    if (!result) {
      return c.json({
        success: false,
        error: 'Batch not found or no trial data available'
      }, 404);
    }

    switch (format) {
      case 'markdown': {
        const content = exportToMarkdown(result);
        return new Response(content, {
          headers: {
            'Content-Type': 'text/markdown; charset=utf-8',
            'Content-Disposition': `attachment; filename="statistics_${batchId}.md"`,
          },
        });
      }

      case 'csv': {
        const content = exportToCSV(result);
        return new Response(content, {
          headers: {
            'Content-Type': 'text/csv; charset=utf-8',
            'Content-Disposition': `attachment; filename="statistics_${batchId}.csv"`,
          },
        });
      }

      case 'summary': {
        const content = exportSummaryTable(result);
        return new Response(content, {
          headers: {
            'Content-Type': 'text/markdown; charset=utf-8',
            'Content-Disposition': `attachment; filename="statistics_summary_${batchId}.md"`,
          },
        });
      }

      default:
        return c.json({
          success: false,
          error: `Unsupported format: ${format}. Supported: markdown, csv, summary`
        }, 400);
    }
  } catch (error) {
    console.error('Failed to export statistics:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

export { batchExperimentRoutes };

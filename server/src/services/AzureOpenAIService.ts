/**
 * Azure OpenAI API ã‚µãƒ¼ãƒ“ã‚¹
 * OpenAI SDKçµŒç”±ã§Azure OpenAI Serviceã«ã‚¢ã‚¯ã‚»ã‚¹
 *
 * APIã‚­ãƒ¼èªè¨¼ã‚’ä½¿ç”¨ï¼ˆEntra IDã§ã¯ãªã„ï¼‰
 * å¯¾å¿œãƒ¢ãƒ‡ãƒ«: GPT-4.1, GPT-4.1 Mini, GPT-5 Chat, GPT-5 Mini, Model Router
 */

import OpenAI from "openai";
import type { GeminiResponseMetrics } from "../types/metrics.types";

/**
 * Azure OpenAI API ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‹ï¼ˆè¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰
 * GeminiServiceã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç¶­æŒ
 */
export interface AzureOpenAIResponse {
  success: boolean;
  data?: any;
  error?: string;
  /** è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ */
  metrics?: GeminiResponseMetrics;
}

/** ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆAPIãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆGPT-4.1ç³»ï¼‰ */
export const DEFAULT_API_VERSION = "2024-12-01-preview";

/** GPT-5-chatç”¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆResponses APIï¼‰ */
export const GPT5_RESPONSES_API_VERSION = "2025-04-01-preview";

/** GPT-5-miniç”¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆChat Completions API + reasoning_effortï¼‰ */
export const GPT5_MINI_API_VERSION = "2025-03-01-preview";

/**
 * Responses APIã‚’ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š
 * GPT-5-chatã®ã¿Responses APIã‚’ä½¿ç”¨ï¼ˆæ¨è«–æ©Ÿèƒ½ã‚’æ´»ç”¨ï¼‰
 */
function useResponsesApi(modelId: string): boolean {
  return modelId === "gpt-5-chat";
}

/**
 * GPT-5-miniã‹ã©ã†ã‹ã‚’åˆ¤å®š
 * Chat Completions API + reasoning_effort="minimal" ã‚’ä½¿ç”¨
 */
function isGpt5Mini(modelId: string): boolean {
  return modelId === "gpt-5-mini";
}

/** åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«IDä¸€è¦§ */
export const AZURE_AVAILABLE_MODELS = [
  "gpt-4.1",
  "gpt-4.1-mini",
  "gpt-5-chat",
  "gpt-5-mini",
  "model-router"
] as const;

export type AzureModelId = typeof AZURE_AVAILABLE_MODELS[number];

/**
 * ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã®ç’°å¢ƒå¤‰æ•°ã‚­ãƒ¼ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
 */
const MODEL_TO_DEPLOYMENT_ENV: Record<string, string> = {
  "gpt-4.1": "AZURE_OPENAI_DEPLOYMENT_GPT4_1_VANILLA",
  "gpt-4.1-mini": "AZURE_OPENAI_DEPLOYMENT_GPT4_1_MINI",
  "gpt-5-chat": "AZURE_OPENAI_DEPLOYMENT_GPT5_CHAT",
  "gpt-5-mini": "AZURE_OPENAI_DEPLOYMENT_GPT5_MINI",
  "model-router": "AZURE_OPENAI_DEPLOYMENT_MODEL_ROUTER",
};

/**
 * ãƒ¢ãƒ‡ãƒ«IDã«å¿œã˜ãŸAzure OpenAIæ¥ç¶šè¨­å®šã‚’å–å¾—
 * å…¨ãƒ¢ãƒ‡ãƒ«å…±é€šã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ»APIã‚­ãƒ¼ã‚’ä½¿ç”¨
 * @param modelId ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
 * @returns ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€APIã‚­ãƒ¼ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
 */
function getAzureConfig(modelId: string): { endpoint: string; apiKey: string; deploymentName: string } {
  const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
  const apiKey = process.env.AZURE_OPENAI_API_KEY;

  if (!endpoint) {
    throw new Error("AZURE_OPENAI_ENDPOINT environment variable is not set");
  }
  if (!apiKey) {
    throw new Error("AZURE_OPENAI_API_KEY environment variable is not set");
  }

  // ãƒ¢ãƒ‡ãƒ«IDã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã®ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
  const deploymentEnvKey = MODEL_TO_DEPLOYMENT_ENV[modelId];
  if (!deploymentEnvKey) {
    throw new Error(`Unknown model ID: ${modelId}. Available models: ${AZURE_AVAILABLE_MODELS.join(", ")}`);
  }

  const deploymentName = process.env[deploymentEnvKey];
  if (!deploymentName) {
    throw new Error(`${deploymentEnvKey} environment variable is not set`);
  }

  // ãƒ‡ãƒãƒƒã‚°: ãƒ¢ãƒ‡ãƒ«IDã¨ç’°å¢ƒå¤‰æ•°ã®å¯¾å¿œã‚’å‡ºåŠ›
  console.log(`ğŸ” getAzureConfig: modelId="${modelId}" -> envKey="${deploymentEnvKey}" -> deploymentName="${deploymentName}"`);

  return { endpoint, apiKey, deploymentName };
}

/**
 * Azure OpenAI ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹
 * OpenAI SDKã‚’ä½¿ç”¨ã—ã¦Azure OpenAIã«ã‚¢ã‚¯ã‚»ã‚¹
 */
export class AzureOpenAIService {
  private client: OpenAI;
  private deploymentName: string;
  private modelId: string;
  private baseURL: string;
  private apiVersion: string;
  private useResponsesApi: boolean;
  private isGpt5Mini: boolean;

  /**
   * ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
   * @param endpoint Azure OpenAI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
   * @param apiKey Azure OpenAI APIã‚­ãƒ¼
   * @param modelId ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
   * @param deploymentName ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
   * @param apiVersion APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
   */
  constructor(
    endpoint: string,
    apiKey: string,
    modelId: string,
    deploymentName: string,
    apiVersion?: string
  ) {
    if (!endpoint) {
      throw new Error("AZURE_OPENAI_ENDPOINT is required");
    }
    if (!apiKey) {
      throw new Error("AZURE_OPENAI_API_KEY is required");
    }
    if (!deploymentName) {
      throw new Error("deploymentName is required");
    }

    this.modelId = modelId;
    this.deploymentName = deploymentName;

    // ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’åˆ¤å®š
    this.useResponsesApi = useResponsesApi(modelId);  // GPT-5-chatã®ã¿true
    this.isGpt5Mini = isGpt5Mini(modelId);            // GPT-5-miniã®ã¿true

    // APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ±ºå®š
    // - GPT-5-chat: Responses APIç”¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    // - GPT-5-mini: Chat Completions API + reasoning_effortç”¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    // - ãã®ä»–: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³
    if (apiVersion) {
      this.apiVersion = apiVersion;
    } else if (this.useResponsesApi) {
      this.apiVersion = GPT5_RESPONSES_API_VERSION;
    } else if (this.isGpt5Mini) {
      this.apiVersion = GPT5_MINI_API_VERSION;
    } else {
      this.apiVersion = DEFAULT_API_VERSION;
    }

    // ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ™ãƒ¼ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆæœ«å°¾ã®ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’é™¤å»ï¼‰
    const normalizedEndpoint = endpoint.replace(/\/$/, '');

    // URLã‚’æ§‹ç¯‰
    // GPT-5ç³»: /openai/responses ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
    // ãã®ä»–: /openai/deployments/{deploymentName} ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
    if (this.useResponsesApi) {
      this.baseURL = `${normalizedEndpoint}/openai`;
    } else {
      this.baseURL = `${normalizedEndpoint}/openai/deployments/${this.deploymentName}`;
    }

    // ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°å‡ºåŠ›
    console.log('ğŸ”§ AzureOpenAIService initialization:');
    console.log(`   Model ID: ${this.modelId}`);
    console.log(`   Deployment Name: ${this.deploymentName}`);
    console.log(`   Base URL: ${this.baseURL}`);
    console.log(`   API Version: ${this.apiVersion}`);
    console.log(`   Use Responses API: ${this.useResponsesApi}`);
    console.log(`   Is GPT-5-mini: ${this.isGpt5Mini}`);

    // OpenAI SDKã‚’Azureç”¨ã«è¨­å®š
    this.client = new OpenAI({
      apiKey,
      baseURL: this.baseURL,
      defaultQuery: { 'api-version': this.apiVersion },
      defaultHeaders: { 'api-key': apiKey },
    });
  }

  /**
   * JSONå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆï¼ˆè¨ˆæ¸¬æ©Ÿèƒ½ä»˜ãï¼‰
   * @param prompt ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
   * @returns JSONå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆè¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
   */
  async generateJSON(prompt: string): Promise<AzureOpenAIResponse> {
    const startTime = Date.now();

    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    const expectedUrl = this.useResponsesApi
      ? `${this.baseURL}/responses?api-version=${this.apiVersion}`
      : `${this.baseURL}/chat/completions?api-version=${this.apiVersion}`;
    console.log('ğŸŒ AzureOpenAI generateJSON request:');
    console.log(`   Expected URL: ${expectedUrl}`);
    console.log(`   Model: ${this.modelId}`);
    console.log(`   Deployment: ${this.deploymentName}`);

    try {
      // JSONå½¢å¼ã§ã®å¿œç­”ã‚’è¦æ±‚
      const fullPrompt = `${prompt}\n\nIMPORTANT: Respond ONLY with valid JSON. Do not include any markdown formatting, explanations, or text outside the JSON structure.`;

      let result: OpenAI.Chat.Completions.ChatCompletion;

      if (this.useResponsesApi) {
        // GPT-5-chat: Responses API ã‚’ä½¿ç”¨
        // æ³¨æ„: Azure OpenAI Responses APIã§ã¯ reasoning ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯éå¯¾å¿œ
        console.log('   Using Responses API for GPT-5-chat model');
        const responsesResult = await (this.client as any).responses.create({
          model: this.deploymentName,
          input: fullPrompt,
          text: {
            format: { type: "json_object" }
          }
        });

        // ãƒ‡ãƒãƒƒã‚°: Responses APIã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        console.log('   ğŸ“Š Responses API raw usage:', JSON.stringify(responsesResult.usage, null, 2));

        // Responses API ã®çµæœã‚’ Chat Completions å½¢å¼ã«å¤‰æ›
        // æ³¨æ„: Responses APIã¯ input_tokens/output_tokens ã‚’è¿”ã™ï¼ˆChat Completions APIã¯ prompt_tokens/completion_tokensï¼‰
        const outputText = responsesResult.output_text || "";
        const responsesUsage = responsesResult.usage || {};
        result = {
          id: responsesResult.id || "",
          object: "chat.completion",
          created: Date.now(),
          model: this.deploymentName,
          choices: [{
            index: 0,
            message: {
              role: "assistant",
              content: outputText,
              refusal: null
            },
            finish_reason: "stop",
            logprobs: null
          }],
          // Responses APIã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’Chat Completionså½¢å¼ã«å¤‰æ›
          usage: {
            prompt_tokens: responsesUsage.input_tokens || 0,
            completion_tokens: responsesUsage.output_tokens || 0,
            total_tokens: responsesUsage.total_tokens || 0
          }
        };
      } else if (this.isGpt5Mini) {
        // GPT-5-mini: Chat Completions API + reasoning_effort="minimal"
        console.log('   Using Chat Completions API for GPT-5-mini (reasoning_effort: minimal)');
        result = await this.client.chat.completions.create({
          model: this.deploymentName,
          messages: [
            {
              role: "user",
              content: fullPrompt,
            },
          ],
          response_format: { type: "json_object" },
          reasoning_effort: "minimal",     // æ¨è«–ã‚’æœ€å°åŒ–
          max_completion_tokens: 4096,     // æ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        } as any);  // reasoning_effortã®å‹å®šç¾©ãŒãªã„å ´åˆã®ãŸã‚
      } else {
        // GPT-4.1ç³»ãªã©: Chat Completions API ã‚’ä½¿ç”¨
        console.log('   Using Chat Completions API');
        result = await this.client.chat.completions.create({
          model: this.deploymentName,
          messages: [
            {
              role: "user",
              content: fullPrompt,
            },
          ],
          response_format: { type: "json_object" },
        });
      }

      const endTime = Date.now();

      // è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
      const metrics = this.extractMetrics(result, startTime, endTime);
      console.log('ğŸ“Š AzureOpenAIService metrics:', metrics);

      const text = result.choices[0]?.message?.content || "";

      // JSONã‚’ãƒ‘ãƒ¼ã‚¹
      let jsonData;
      try {
        // ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤ï¼ˆå¿µã®ãŸã‚ï¼‰
        const cleanedText = text.replace(/```json\n?/g, "").replace(/```\n?/g, "").trim();
        jsonData = JSON.parse(cleanedText);
      } catch (parseError) {
        console.error("JSON parse error:", parseError);
        console.error("Raw response:", text);
        return {
          success: false,
          error: `Failed to parse JSON response: ${parseError}`,
          metrics
        };
      }

      return {
        success: true,
        data: jsonData,
        metrics
      };
    } catch (error) {
      const endTime = Date.now();
      console.error("âŒ Azure OpenAI API error:", error);
      // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
      if (error instanceof Error) {
        console.error(`   Error name: ${error.name}`);
        console.error(`   Error message: ${error.message}`);
        if ('status' in error) {
          console.error(`   HTTP Status: ${(error as any).status}`);
        }
        if ('response' in error) {
          console.error(`   Response:`, (error as any).response);
        }
      }
      return {
        success: false,
        error: error instanceof Error ? error.message : "Unknown error",
        metrics: {
          promptTokens: 0,
          responseTokens: 0,
          totalTokens: 0,
          processingTimeMs: endTime - startTime
        }
      };
    }
  }

  /**
   * ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
   * @param result OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
   * @param startTime é–‹å§‹æ™‚åˆ»
   * @param endTime çµ‚äº†æ™‚åˆ»
   */
  private extractMetrics(result: OpenAI.Chat.Completions.ChatCompletion, startTime: number, endTime: number): GeminiResponseMetrics {
    const usage = result.usage || {};

    const promptTokens = usage.prompt_tokens || 0;
    const responseTokens = usage.completion_tokens || 0;
    const totalTokens = usage.total_tokens || (promptTokens + responseTokens);

    // model-routerä½¿ç”¨æ™‚: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®modelãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åãŒå«ã¾ã‚Œã‚‹
    // ä¾‹: "gpt-4.1-nano-2025-04-14", "gpt-5-chat-2025-03-27" ãªã©
    const selectedModel = this.modelId === 'model-router' ? result.model : undefined;

    return {
      promptTokens,
      responseTokens,
      totalTokens,
      processingTimeMs: endTime - startTime,
      selectedModel,
    };
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆï¼ˆè¨ˆæ¸¬æ©Ÿèƒ½ä»˜ãï¼‰
   * @param prompt ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
   * @returns ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆè¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
   */
  async generateText(prompt: string): Promise<AzureOpenAIResponse> {
    const startTime = Date.now();

    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    const expectedUrl = this.useResponsesApi
      ? `${this.baseURL}/responses?api-version=${this.apiVersion}`
      : `${this.baseURL}/chat/completions?api-version=${this.apiVersion}`;
    console.log('ğŸŒ AzureOpenAI generateText request:');
    console.log(`   Expected URL: ${expectedUrl}`);
    console.log(`   Model: ${this.modelId}`);
    console.log(`   Deployment: ${this.deploymentName}`);

    try {
      let result: OpenAI.Chat.Completions.ChatCompletion;

      if (this.useResponsesApi) {
        // GPT-5-chat: Responses API ã‚’ä½¿ç”¨
        // æ³¨æ„: Azure OpenAI Responses APIã§ã¯ reasoning ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯éå¯¾å¿œ
        console.log('   Using Responses API for GPT-5-chat model');
        const responsesResult = await (this.client as any).responses.create({
          model: this.deploymentName,
          input: prompt,
        });

        // ãƒ‡ãƒãƒƒã‚°: Responses APIã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        console.log('   ğŸ“Š Responses API raw usage (text):', JSON.stringify(responsesResult.usage, null, 2));

        // Responses API ã®çµæœã‚’ Chat Completions å½¢å¼ã«å¤‰æ›
        // æ³¨æ„: Responses APIã¯ input_tokens/output_tokens ã‚’è¿”ã™ï¼ˆChat Completions APIã¯ prompt_tokens/completion_tokensï¼‰
        const outputText = responsesResult.output_text || "";
        const responsesUsage = responsesResult.usage || {};
        result = {
          id: responsesResult.id || "",
          object: "chat.completion",
          created: Date.now(),
          model: this.deploymentName,
          choices: [{
            index: 0,
            message: {
              role: "assistant",
              content: outputText,
              refusal: null
            },
            finish_reason: "stop",
            logprobs: null
          }],
          // Responses APIã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’Chat Completionså½¢å¼ã«å¤‰æ›
          usage: {
            prompt_tokens: responsesUsage.input_tokens || 0,
            completion_tokens: responsesUsage.output_tokens || 0,
            total_tokens: responsesUsage.total_tokens || 0
          }
        };
      } else if (this.isGpt5Mini) {
        // GPT-5-mini: Chat Completions API + reasoning_effort="minimal"
        console.log('   Using Chat Completions API for GPT-5-mini (reasoning_effort: minimal)');
        result = await this.client.chat.completions.create({
          model: this.deploymentName,
          messages: [
            {
              role: "user",
              content: prompt,
            },
          ],
          reasoning_effort: "minimal",     // æ¨è«–ã‚’æœ€å°åŒ–
          max_completion_tokens: 4096,     // æ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        } as any);  // reasoning_effortã®å‹å®šç¾©ãŒãªã„å ´åˆã®ãŸã‚
      } else {
        // GPT-4.1ç³»ãªã©: Chat Completions API ã‚’ä½¿ç”¨
        console.log('   Using Chat Completions API');
        result = await this.client.chat.completions.create({
          model: this.deploymentName,
          messages: [
            {
              role: "user",
              content: prompt,
            },
          ],
        });
      }

      const endTime = Date.now();

      // è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
      const metrics = this.extractMetrics(result, startTime, endTime);
      console.log('ğŸ“Š AzureOpenAIService metrics (text):', metrics);

      const text = result.choices[0]?.message?.content || "";

      return {
        success: true,
        data: text,
        metrics
      };
    } catch (error) {
      const endTime = Date.now();
      console.error("âŒ Azure OpenAI API error (text):", error);
      // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
      if (error instanceof Error) {
        console.error(`   Error name: ${error.name}`);
        console.error(`   Error message: ${error.message}`);
        if ('status' in error) {
          console.error(`   HTTP Status: ${(error as any).status}`);
        }
        if ('response' in error) {
          console.error(`   Response:`, (error as any).response);
        }
      }
      return {
        success: false,
        error: error instanceof Error ? error.message : "Unknown error",
        metrics: {
          promptTokens: 0,
          responseTokens: 0,
          totalTokens: 0,
          processingTimeMs: endTime - startTime
        }
      };
    }
  }

  /**
   * ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«IDã‚’å–å¾—
   */
  getModelId(): string {
    return this.modelId;
  }

  /**
   * ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã‚’å–å¾—
   */
  getDeploymentName(): string {
    return this.deploymentName;
  }
}

/**
 * AzureOpenAIServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
 * ãƒ¢ãƒ‡ãƒ«IDã«å¿œã˜ã¦é©åˆ‡ãªç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šè¨­å®šã‚’å–å¾—
 * @param modelId ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
 */
export function createAzureOpenAIService(modelId: string): AzureOpenAIService {
  const config = getAzureConfig(modelId);
  const apiVersion = process.env.AZURE_OPENAI_API_VERSION;

  return new AzureOpenAIService(
    config.endpoint,
    config.apiKey,
    modelId,
    config.deploymentName,
    apiVersion
  );
}

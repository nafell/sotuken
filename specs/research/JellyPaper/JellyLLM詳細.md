# JellyLLM詳細

*Exported on: 2025/10/11 20:03:17*

承知いたしました。Generative and Malleable User Interfaces (GMUI) のプロトタイプシステム「Jelly」における、**プロンプトの利用方法**と**LLM APIの呼び出し**に関する技術的な詳細について、ソースに基づいて詳しく解説します。

Jellyのパイプラインは、ユーザーからのプロンプトを基点とし、LLMを戦略的に利用することで、UIの生成と進化を動的に行います。

## 1. LLM API呼び出しの技術スタックと最適化

Jellyシステムは、以下のLLMモデルをバックエンドとして利用しています。

• **AnthropicのClaude 3.5 Sonnet**

• **OpenAIのGPT-4o**

これらのモデルは、内部的なパフォーマンステストに基づいて、パイプラインの様々なタスクのために選択されました。

### 1.1. 処理の並行処理とパフォーマンス最適化

パフォーマンスを最適化するため、パイプラインは**独立したLLMリクエストを並行して処理する**ように開発されています。

### 1.2. コンテキストの組み込みとFew-shot prompting

生成ステップの信頼性と正確性を確保するため、以下の技術が用いられています。

1. **コンテキストの組み込み:** 各生成ステップにおいて、**ユーザーの以前のリクエスト**がコンテキストとして組み込まれます。

2. **Few-shot prompting:** 制御された正確な出力を得るために、各ステップに合わせて調整された**フューショットプロンプティング**が利用されます。

3. **JSON出力の指示:** LLMには、ユーザーの現在のプロンプトからタスクを推論し、**指定された応答フォーマットに従ってJSONオブジェクトを生成する**よう指示されます。

## 2. プロンプトの役割とパイプラインにおける利用

プロンプトは、UI生成プロセスの起点であり、UIの継続的な進化の駆動源です。

### 2.1. 初期プロンプト (Initial Prompt)

ユーザーがJellyを開いて最初に入力するプロンプトです（例：「友人と夕食会を開く予定です (I am hosting a dinner party with my friends!)」）。

**役割:**

• **タスクの推論:** LLMベースのタスク分析ステップにおいて、ユーザーの目標とサブタスクを推論するために解析されます。

• **データモデルの生成:** この分析結果に基づき、LLMがタスク構造を記述する**タスク駆動型データモデル**（オブジェクト指向関係スキーマ、依存関係グラフ、構造化データ）を生成します。

### 2.2. 継続的なプロンプト（Follow-up Prompts）

タスクが進化するにつれて、ユーザーはチャットビューを通じてフォローアップの要求（継続的なプロンプト）を提供します（例：「Aliceと私はビーガンです (Alice and I are both vegan.)」）。

**役割とLLMの処理:**

1. **コンテキストの利用:** システムは、**以前のプロンプトと既存のデータモデル**をコンテキストとして活用します。

2. **更新操作の決定:** LLMにクエリを実行し、要求が**スキーマの変更**（エンティティや属性の追加、削除、更新）と**データへの更新**のどちらを必要とするかを判断します。

3. **操作シーケンスの解析:** 要求は、以下の構造を持つ操作シーケンスに解析されます。 $\text{Updater} := {\text{Target}, \text{Action}, \text{Specifications}} \quad$

    ◦ **Action**には、スキーマとデータの両方に対する `add`、`remove`、`update` のほか、データ固有の操作（`cluster`、`filter`、`sort`）が含まれます。

4. **UIの動的更新:** LLMは、UIを更新するために必要な操作を生成し、これが基礎となるデータモデルの変更に翻訳され、UIのリアルタイムな更新を駆動します。

## 3. LLM生成結果の検証

LLMが生成したスキーマやデータ、および依存関係の正確性を保証するため、パイプラインには検証ステップが含まれています。

• **互換性チェック:** パイプラインは、レンダリング前に生成されたスキーマとデータに対して**互換性チェック**を実行します。

• **依存関係の検証:** LLMが依存関係（特に方向性のある関係）を確立する際、**正確性を確保するための検証**がパイプラインに組み込まれています。これは、関係性が逆転するエラーやスキーマ内で冗長な依存関係が発生する問題を軽減するために重要です。

## 4. プロンプトの成功率と課題

技術評価の結果、LLMはユーザーの自然言語プロンプトで表現された情報およびインタラクションのニーズを満たす、関連性の高いエンティティと依存関係を**確実に生成できる**ことが示されています。

しかし、ユーザー調査では、プロンプトに起因する以下の課題が観察されています。

1. **UIの視覚的スタイルのカスタマイズ失敗:** ユーザーが「テキストサイズを小さくできますか？」など、UIの視覚的スタイル変更を要求した場合、JellyのUI仕様の包括性の限界により、スキーマやデータへの変更が行われず、要求に対応できませんでした。

2. **意図したタスク構造の生成失敗:** アクティビティを複数のカテゴリー（食、歴史、博物館など）に分けて、それぞれ別の行にリストとして表示することを要求された際、Jellyは既存のすべてのアクティビティに「タイプ」属性を追加するに留まり、意図されたリスト構造の作成に失敗しました。

これらの失敗事例は、現在のLLM駆動のパイプラインが、ユーザーの意図を正確に**高レベルのUI仕様や設計パターン**にマッピングする部分（特にレイアウトや高度なインタラクションロジック）において、さらなる拡張が必要であることを示しています。
